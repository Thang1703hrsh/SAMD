{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3324de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T08:32:12.150151Z",
     "iopub.status.busy": "2026-01-14T08:32:12.149833Z",
     "iopub.status.idle": "2026-01-14T08:32:43.238427Z",
     "shell.execute_reply": "2026-01-14T08:32:43.237685Z"
    },
    "papermill": {
     "duration": 31.122646,
     "end_time": "2026-01-14T08:32:43.240232",
     "exception": false,
     "start_time": "2026-01-14T08:32:12.117586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install llm2vec\n",
    "# !pip install -U \"transformers\" \"huggingface_hub\" \"tokenizers\"\n",
    "!pip install Levenshtein\n",
    "!pip install \"protobuf==3.20.3\" --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec678c1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-14T08:32:43.301083Z",
     "iopub.status.busy": "2026-01-14T08:32:43.300779Z",
     "iopub.status.idle": "2026-01-14T08:33:21.124718Z",
     "shell.execute_reply": "2026-01-14T08:33:21.124107Z"
    },
    "papermill": {
     "duration": 37.856187,
     "end_time": "2026-01-14T08:33:21.126576",
     "exception": false,
     "start_time": "2026-01-14T08:32:43.270389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, math, pandas as pd, numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Union, Optional\n",
    "import torch\n",
    "import Levenshtein\n",
    "from typing import List, Sequence, Tuple\n",
    "from transformers import (AutoTokenizer, AutoConfig, AutoModelForSequenceClassification,\n",
    "                          TrainingArguments, Trainer, DataCollatorWithPadding)\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "import editdistance\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from peft import PeftModel\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from transformers import get_scheduler\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import kagglehub\n",
    "import random\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from types import SimpleNamespace\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=SyntaxWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf3a7d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T08:33:21.186360Z",
     "iopub.status.busy": "2026-01-14T08:33:21.185707Z",
     "iopub.status.idle": "2026-01-14T08:33:21.199890Z",
     "shell.execute_reply": "2026-01-14T08:33:21.199331Z"
    },
    "papermill": {
     "duration": 0.045382,
     "end_time": "2026-01-14T08:33:21.201225",
     "exception": false,
     "start_time": "2026-01-14T08:33:21.155843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TASK_TYPE = \"pair_cls\"\n",
    "MAX_LENGTH = 256\n",
    "BATCH_SIZE = 16\n",
    "epochs = 5\n",
    "LR = 2e-5\n",
    "warmup_ratio = 0.06\n",
    "save_dir = 'ckpt1'\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "teacher_special=\"<|embed|>\"\n",
    "student_special=\"[CLS]\"\n",
    "###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc90a2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T08:33:21.261556Z",
     "iopub.status.busy": "2026-01-14T08:33:21.261274Z",
     "iopub.status.idle": "2026-01-14T08:33:21.278245Z",
     "shell.execute_reply": "2026-01-14T08:33:21.277438Z"
    },
    "papermill": {
     "duration": 0.048948,
     "end_time": "2026-01-14T08:33:21.279741",
     "exception": false,
     "start_time": "2026-01-14T08:33:21.230793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TextPairRaw(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, task: str):\n",
    "        self.task = task\n",
    "        if task == \"single_cls\":\n",
    "            self.samples = [(t, None, int(y)) for t, y in zip(df[\"text\"].astype(str), df[\"label\"].astype(int))]\n",
    "        elif task == \"pair_cls\":\n",
    "            self.samples = [(a, b) for a,b in zip(df[\"premise\"].astype(str),\n",
    "                                                            df[\"hypothesis\"].astype(str))]\n",
    "        else:  # pair_reg\n",
    "            self.samples = [(a, b) for a,b in zip(df[\"sentence1\"].astype(str),\n",
    "                                                              df[\"sentence2\"].astype(str))]\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, idx): return self.samples[idx] \n",
    "from typing import List, Tuple, Optional\n",
    "\n",
    "\n",
    "\n",
    "class DualTokenizerCollate:\n",
    "    \"\"\"Collate that tokenizes with two tokenizers (student/teacher).\n",
    "\n",
    "    Span-MinED upgrade: if a tokenizer is *fast*, we also return `offset_mapping`\n",
    "    so attention alignment can be done via character-span overlap (robust 1-to-many).\n",
    "    For slow tokenizers, we simply omit offsets (and downstream code falls back).\n",
    "    \"\"\"\n",
    "    def __init__(self, tok_student, tok_teacher, task: str, max_len: int):\n",
    "        self.ts = tok_student\n",
    "        self.tt = tok_teacher\n",
    "        self.task = task\n",
    "        self.max_len = max_len\n",
    "\n",
    "        self._stu_fast = bool(getattr(tok_student, \"is_fast\", False))\n",
    "        self._tea_fast = bool(getattr(tok_teacher, \"is_fast\", False))\n",
    "\n",
    "    def _encode(self, tok, texts, want_offsets: bool):\n",
    "        kwargs = dict(\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "            return_special_tokens_mask=True,\n",
    "        )\n",
    "        # `return_offsets_mapping` is only supported by *fast* tokenizers.\n",
    "        if want_offsets:\n",
    "            kwargs[\"return_offsets_mapping\"] = True\n",
    "        return tok(list(texts), **kwargs)\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        # Supported batch formats:\n",
    "        # - single_cls: (text, None, label)\n",
    "        # - pair_*: (s1, s2)\n",
    "        if self.task == \"single_cls\":\n",
    "            texts, labels = [], []\n",
    "            for item in batch:\n",
    "                # tolerate both (text, y) and (text, _, y)\n",
    "                if len(item) == 2:\n",
    "                    t, y = item\n",
    "                else:\n",
    "                    t, _, y = item\n",
    "                texts.append(t)\n",
    "                labels.append(int(y))\n",
    "\n",
    "            s_enc = self._encode(self.ts, texts, self._stu_fast)\n",
    "            t_enc = self._encode(self.tt, texts, self._tea_fast)\n",
    "\n",
    "            out = {\n",
    "                \"input_ids_stu\": s_enc[\"input_ids\"],\n",
    "                \"attention_mask_stu\": s_enc[\"attention_mask\"],\n",
    "                \"special_tokens_mask_stu\": s_enc[\"special_tokens_mask\"],\n",
    "                \"input_ids_tea\": t_enc[\"input_ids\"],\n",
    "                \"attention_mask_tea\": t_enc[\"attention_mask\"],\n",
    "                \"special_tokens_mask_tea\": t_enc[\"special_tokens_mask\"],\n",
    "                \"labels\": torch.tensor(labels, dtype=torch.long),\n",
    "            }\n",
    "            if \"token_type_ids\" in s_enc:\n",
    "                out[\"token_type_ids_stu\"] = s_enc[\"token_type_ids\"]\n",
    "            if \"token_type_ids\" in t_enc:\n",
    "                out[\"token_type_ids_tea\"] = t_enc[\"token_type_ids\"]\n",
    "\n",
    "            # Offsets (fast tokenizers only)\n",
    "            if \"offset_mapping\" in s_enc:\n",
    "                out[\"offset_mapping_stu\"] = s_enc[\"offset_mapping\"]\n",
    "            if \"offset_mapping\" in t_enc:\n",
    "                out[\"offset_mapping_tea\"] = t_enc[\"offset_mapping\"]\n",
    "            return out\n",
    "\n",
    "        # ------- pair (bi-encoder) -------\n",
    "        s1s, s2s = zip(*batch)\n",
    "\n",
    "        s1_enc = self._encode(self.ts, s1s, self._stu_fast)\n",
    "        s2_enc = self._encode(self.ts, s2s, self._stu_fast)\n",
    "\n",
    "        t1_enc = self._encode(self.tt, s1s, self._tea_fast)\n",
    "        t2_enc = self._encode(self.tt, s2s, self._tea_fast)\n",
    "\n",
    "        out = {\n",
    "            # student\n",
    "            \"input_ids1_stu\": s1_enc[\"input_ids\"],\n",
    "            \"attention_mask1_stu\": s1_enc[\"attention_mask\"],\n",
    "            \"special_tokens_mask1_stu\": s1_enc[\"special_tokens_mask\"],\n",
    "            \"input_ids2_stu\": s2_enc[\"input_ids\"],\n",
    "            \"attention_mask2_stu\": s2_enc[\"attention_mask\"],\n",
    "            \"special_tokens_mask2_stu\": s2_enc[\"special_tokens_mask\"],\n",
    "\n",
    "            # teacher\n",
    "            \"input_ids1_tea\": t1_enc[\"input_ids\"],\n",
    "            \"attention_mask1_tea\": t1_enc[\"attention_mask\"],\n",
    "            \"special_tokens_mask1_tea\": t1_enc[\"special_tokens_mask\"],\n",
    "            \"input_ids2_tea\": t2_enc[\"input_ids\"],\n",
    "            \"attention_mask2_tea\": t2_enc[\"attention_mask\"],\n",
    "            \"special_tokens_mask2_tea\": t2_enc[\"special_tokens_mask\"],\n",
    "        }\n",
    "\n",
    "        if \"token_type_ids\" in s1_enc:\n",
    "            out[\"token_type_ids1_stu\"] = s1_enc[\"token_type_ids\"]\n",
    "        if \"token_type_ids\" in s2_enc:\n",
    "            out[\"token_type_ids2_stu\"] = s2_enc[\"token_type_ids\"]\n",
    "        if \"token_type_ids\" in t1_enc:\n",
    "            out[\"token_type_ids1_tea\"] = t1_enc[\"token_type_ids\"]\n",
    "        if \"token_type_ids\" in t2_enc:\n",
    "            out[\"token_type_ids2_tea\"] = t2_enc[\"token_type_ids\"]\n",
    "\n",
    "        # Offsets (fast tokenizers only)\n",
    "        if \"offset_mapping\" in s1_enc:\n",
    "            out[\"offset_mapping1_stu\"] = s1_enc[\"offset_mapping\"]\n",
    "        if \"offset_mapping\" in s2_enc:\n",
    "            out[\"offset_mapping2_stu\"] = s2_enc[\"offset_mapping\"]\n",
    "        if \"offset_mapping\" in t1_enc:\n",
    "            out[\"offset_mapping1_tea\"] = t1_enc[\"offset_mapping\"]\n",
    "        if \"offset_mapping\" in t2_enc:\n",
    "            out[\"offset_mapping2_tea\"] = t2_enc[\"offset_mapping\"]\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "print(\"Done Prepare Dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc70d4c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T08:33:21.338406Z",
     "iopub.status.busy": "2026-01-14T08:33:21.338141Z",
     "iopub.status.idle": "2026-01-14T08:33:21.342370Z",
     "shell.execute_reply": "2026-01-14T08:33:21.341785Z"
    },
    "papermill": {
     "duration": 0.034933,
     "end_time": "2026-01-14T08:33:21.343635",
     "exception": false,
     "start_time": "2026-01-14T08:33:21.308702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def info_nce(q, k, temperature=0.07, neg_valid_mask=None):\n",
    "    q = F.normalize(q, dim=-1)\n",
    "    k = F.normalize(k, dim=-1)\n",
    "\n",
    "    logits = torch.matmul(q, k.T) / temperature\n",
    "    labels = torch.arange(q.size(0), device=q.device)\n",
    "    loss_inbatch = F.cross_entropy(logits, labels) \n",
    "    return loss_inbatch, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a15c70a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T08:33:21.403837Z",
     "iopub.status.busy": "2026-01-14T08:33:21.403200Z",
     "iopub.status.idle": "2026-01-14T08:33:21.499705Z",
     "shell.execute_reply": "2026-01-14T08:33:21.498990Z"
    },
    "papermill": {
     "duration": 0.128611,
     "end_time": "2026-01-14T08:33:21.501310",
     "exception": false,
     "start_time": "2026-01-14T08:33:21.372699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_train = '/kaggle/input/multitask-data/merged_9_data_3k_each_ver2.csv'\n",
    "df = pd.read_csv(data_train)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3650457b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T08:33:21.563716Z",
     "iopub.status.busy": "2026-01-14T08:33:21.563047Z",
     "iopub.status.idle": "2026-01-14T08:33:21.590282Z",
     "shell.execute_reply": "2026-01-14T08:33:21.589475Z"
    },
    "papermill": {
     "duration": 0.0587,
     "end_time": "2026-01-14T08:33:21.591732",
     "exception": false,
     "start_time": "2026-01-14T08:33:21.533032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"premise\"] = df[\"text\"]\n",
    "df[\"hypothesis\"] = df[\"text\"]\n",
    "cols = [\"premise\", \"hypothesis\"]\n",
    "df_out = df[cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6c21e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T08:33:21.651473Z",
     "iopub.status.busy": "2026-01-14T08:33:21.650908Z",
     "iopub.status.idle": "2026-01-14T08:33:32.183871Z",
     "shell.execute_reply": "2026-01-14T08:33:32.183287Z"
    },
    "papermill": {
     "duration": 10.564973,
     "end_time": "2026-01-14T08:33:32.185581",
     "exception": false,
     "start_time": "2026-01-14T08:33:21.620608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "student_name = \"huawei-noah/TinyBERT_General_4L_312D\"\n",
    "tok_student = AutoTokenizer.from_pretrained(student_name)\n",
    "model_student = AutoModel.from_pretrained(\n",
    "    student_name,\n",
    "    output_hidden_states=True\n",
    ")\n",
    "\n",
    "tok_teacher = AutoTokenizer.from_pretrained(\"BAAI/bge-m3\")\n",
    "model_teacher = AutoModel.from_pretrained(\n",
    "    \"BAAI/bge-m3\",\n",
    "    output_hidden_states=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35508700",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T08:33:32.247210Z",
     "iopub.status.busy": "2026-01-14T08:33:32.246913Z",
     "iopub.status.idle": "2026-01-14T08:33:32.259710Z",
     "shell.execute_reply": "2026-01-14T08:33:32.258865Z"
    },
    "papermill": {
     "duration": 0.044595,
     "end_time": "2026-01-14T08:33:32.261123",
     "exception": false,
     "start_time": "2026-01-14T08:33:32.216528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "train_ds = TextPairRaw(df_out, TASK_TYPE)\n",
    "\n",
    "collate = DualTokenizerCollate(tok_student, tok_teacher, TASK_TYPE, MAX_LENGTH)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          collate_fn=collate, pin_memory=True, num_workers=2, persistent_workers=True)\n",
    "print(\"Done Prepare Dataloader\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711c2a02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T08:33:32.322919Z",
     "iopub.status.busy": "2026-01-14T08:33:32.322673Z",
     "iopub.status.idle": "2026-01-14T08:33:32.333731Z",
     "shell.execute_reply": "2026-01-14T08:33:32.333081Z"
    },
    "papermill": {
     "duration": 0.043873,
     "end_time": "2026-01-14T08:33:32.335147",
     "exception": false,
     "start_time": "2026-01-14T08:33:32.291274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-uncased')\n",
    "tokenizer = tok_student \n",
    "class STSDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.dataset = pd.read_csv(file_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # instruction = \"Given a text, Retrieve semantically similar text: \"\n",
    "        instruction=\"\"\n",
    "        return {\n",
    "            \"sentence1\": instruction + self.dataset.iloc[idx]['sentence1'],\n",
    "            \"sentence2\": instruction + self.dataset.iloc[idx]['sentence2'],\n",
    "            \"label\": torch.tensor(self.dataset.iloc[idx]['score'], dtype=torch.float),\n",
    "        }\n",
    "        \n",
    "def collate_fn(batch, tokenizer, max_len=128):\n",
    "    s1_list = [item[\"sentence1\"] for item in batch]\n",
    "    s2_list = [item[\"sentence2\"] for item in batch]\n",
    "    labels = torch.stack([item[\"label\"] for item in batch])\n",
    "\n",
    "    enc1 = tokenizer(\n",
    "        s1_list,\n",
    "        truncation=True,\n",
    "        padding=True,       # chỉ pad theo câu dài nhất trong batch\n",
    "        max_length=max_len,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    enc2 = tokenizer(\n",
    "        s2_list,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=max_len,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"input_ids1\": enc1[\"input_ids\"],\n",
    "        \"attention_mask1\": enc1[\"attention_mask\"],\n",
    "        \"input_ids2\": enc2[\"input_ids\"],\n",
    "        \"attention_mask2\": enc2[\"attention_mask\"],\n",
    "        \"labels\": labels,\n",
    "    }\n",
    "\n",
    "def eval_sts(model, eval_loader):\n",
    "    preds, labels = [], []\n",
    "    device = model.device\n",
    "    \n",
    "    with torch.cuda.amp.autocast(dtype=torch.float16):\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(eval_loader):\n",
    "                input_ids1 = batch[\"input_ids1\"].to(device)\n",
    "                attn1 = batch[\"attention_mask1\"].to(device)\n",
    "                input_ids2 = batch[\"input_ids2\"].to(device)\n",
    "                attn2 = batch[\"attention_mask2\"].to(device)\n",
    "                label = batch[\"labels\"]\n",
    "\n",
    "\n",
    "                out1 = model(input_ids=input_ids1, attention_mask=attn1)\n",
    "                out2 = model(input_ids=input_ids2, attention_mask=attn2)\n",
    "\n",
    "                # emb1 = mean_pooling(out1, attn1)\n",
    "                # emb2 = mean_pooling(out2, attn2)\n",
    "                emb1 = out1.last_hidden_state[:, 0, :]\n",
    "                emb2 = out2.last_hidden_state[:, 0, :]\n",
    "                # emb1 = out1.last_hidden_state[:, -1, :]\n",
    "                # emb2 = out2.last_hidden_state[:, -1, :]\n",
    "        \n",
    "                # cosine similarity\n",
    "                sim = F.cosine_similarity(emb1, emb2)\n",
    "                score = (sim + 1) * 2.5  # scale [-1,1] -> [0,5]\n",
    "        \n",
    "                preds.extend(score.cpu().numpy())\n",
    "                labels.extend(label.numpy())\n",
    "    \n",
    "    spearman_corr, _ = spearmanr(preds, labels)\n",
    "    print(f\"Spearman: {spearman_corr:.4f}\")\n",
    "\n",
    "    return spearman_corr\n",
    "\n",
    "\n",
    "def eval_sts_task(model, path_list):\n",
    "    model.eval()\n",
    "    print(' ✅ eval_sts_task')\n",
    "    for path in path_list:\n",
    "        print(path)\n",
    "        eval_dataset = STSDataset(path)\n",
    "        eval_loader = DataLoader(\n",
    "            eval_dataset,\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            collate_fn=lambda x: collate_fn(x, tokenizer)\n",
    "        )\n",
    "        eval_sts(model, eval_loader)\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0a5c79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T08:33:32.396575Z",
     "iopub.status.busy": "2026-01-14T08:33:32.396297Z",
     "iopub.status.idle": "2026-01-14T08:33:32.581103Z",
     "shell.execute_reply": "2026-01-14T08:33:32.580491Z"
    },
    "papermill": {
     "duration": 0.217549,
     "end_time": "2026-01-14T08:33:32.582798",
     "exception": false,
     "start_time": "2026-01-14T08:33:32.365249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import datasets\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def eval_cls(model, eval_loader):\n",
    "    preds, labels = [], []\n",
    "    device = model.device\n",
    "    \n",
    "    with torch.cuda.amp.autocast(dtype=torch.float16):\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(eval_loader):\n",
    "                input_ids1 = batch[\"input_ids1\"].to(device)\n",
    "                attn1 = batch[\"attention_mask1\"].to(device)\n",
    "                label = batch[\"labels\"]\n",
    "\n",
    "                out1 = model(input_ids=input_ids1, attention_mask=attn1)\n",
    "                emb1 = out1.last_hidden_state[:, 0, :]\n",
    "        \n",
    "                preds.extend(emb1.cpu().numpy())\n",
    "                labels.extend(label.numpy())\n",
    "    \n",
    "    return preds, labels\n",
    "\n",
    "class ClasssifyDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.dataset = pd.read_csv(file_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"text\": self.dataset.iloc[idx]['text'],\n",
    "            \"label\": torch.tensor(self.dataset.iloc[idx]['label'], dtype=torch.long),\n",
    "        }\n",
    "\n",
    "def clf_collate_fn(batch, tokenizer, max_len=512):\n",
    "    s1_list = [item[\"text\"] for item in batch]\n",
    "    labels = torch.stack([item[\"label\"] for item in batch])\n",
    "\n",
    "    enc1 = tokenizer(\n",
    "        s1_list,\n",
    "        truncation=True,\n",
    "        padding=True,       # chỉ pad theo câu dài nhất trong batch\n",
    "        max_length=max_len,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"input_ids1\": enc1[\"input_ids\"],\n",
    "        \"attention_mask1\": enc1[\"attention_mask\"],\n",
    "        \"labels\": labels,\n",
    "    }\n",
    "\n",
    "\n",
    "def eval_classification_task(model, path_list):\n",
    "    model.eval()\n",
    "    print(' ✅ eval classifier')\n",
    "\n",
    "    for train_path, dev_path in path_list:\n",
    "        print(dev_path)\n",
    "        eval_dataset = ClasssifyDataset(dev_path)\n",
    "        eval_loader = DataLoader(\n",
    "            eval_dataset,\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            collate_fn=lambda x: clf_collate_fn(x, tokenizer)\n",
    "        )\n",
    "        \n",
    "        train_dataset = ClasssifyDataset(train_path)\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            collate_fn=lambda x: clf_collate_fn(x, tokenizer)\n",
    "        )\n",
    "\n",
    "        X_train, y_train = eval_cls(model, train_loader)\n",
    "        X_test, y_test = eval_cls(model, eval_loader)\n",
    "\n",
    "        clf = LogisticRegression(\n",
    "            random_state=42,\n",
    "            n_jobs=1,\n",
    "            max_iter=200,\n",
    "            verbose=0,\n",
    "        )\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        scores = {}\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        scores[\"accuracy\"] = accuracy\n",
    "        f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "        scores[\"f1\"] = f1\n",
    "        print(scores)\n",
    "        \n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f84d482",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T08:33:32.645063Z",
     "iopub.status.busy": "2026-01-14T08:33:32.644384Z",
     "iopub.status.idle": "2026-01-14T08:33:32.656190Z",
     "shell.execute_reply": "2026-01-14T08:33:32.655660Z"
    },
    "papermill": {
     "duration": 0.043836,
     "end_time": "2026-01-14T08:33:32.657621",
     "exception": false,
     "start_time": "2026-01-14T08:33:32.613785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, average_precision_score\n",
    "\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-uncased')\n",
    "tokenizer = tok_student \n",
    "class PairDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.dataset = pd.read_csv(file_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # instruction = \"Given a text, Retrieve semantically similar text: \"\n",
    "        instruction=\"\"\n",
    "        return {\n",
    "            \"sentence1\": instruction + self.dataset.iloc[idx]['sentence1'],\n",
    "            \"sentence2\": instruction + self.dataset.iloc[idx]['sentence2'],\n",
    "            \"label\": torch.tensor(self.dataset.iloc[idx]['label'], dtype=torch.float),\n",
    "        }\n",
    "        \n",
    "\n",
    "def eval_pair(model, eval_loader):\n",
    "    preds, labels = [], []\n",
    "    device = model.device\n",
    "    \n",
    "    with torch.cuda.amp.autocast(dtype=torch.float16):\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(eval_loader):\n",
    "                input_ids1 = batch[\"input_ids1\"].to(device)\n",
    "                attn1 = batch[\"attention_mask1\"].to(device)\n",
    "                input_ids2 = batch[\"input_ids2\"].to(device)\n",
    "                attn2 = batch[\"attention_mask2\"].to(device)\n",
    "                label = batch[\"labels\"]\n",
    "\n",
    "\n",
    "                out1 = model(input_ids=input_ids1, attention_mask=attn1)\n",
    "                out2 = model(input_ids=input_ids2, attention_mask=attn2)\n",
    "\n",
    "                emb1 = out1.last_hidden_state[:, 0, :]\n",
    "                emb2 = out2.last_hidden_state[:, 0, :]\n",
    "                # emb1 = out1.last_hidden_state[:, -1, :]\n",
    "                # emb2 = out2.last_hidden_state[:, -1, :]\n",
    "        \n",
    "                # cosine similarity\n",
    "                sim = F.cosine_similarity(emb1, emb2)\n",
    "                score = (sim + 1) / 2\n",
    "        \n",
    "                preds.extend(score.cpu().numpy())\n",
    "                labels.extend(label.numpy())\n",
    "    \n",
    "    metric = get_metric_pair_classification(preds, labels)\n",
    "    print(metric)\n",
    "\n",
    "    return metric\n",
    "\n",
    "def get_metric_pair_classification(scores, labels):\n",
    "    best_acc, best_thr = 0, 0\n",
    "    for thr in np.linspace(0, 1, 200):\n",
    "        preds = (scores >= thr).astype(int)\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        if acc > best_acc:\n",
    "            best_acc, best_thr = acc, thr\n",
    "    preds = (scores >= best_thr).astype(int)\n",
    "    return {\n",
    "        \"best_threshold\": best_thr,\n",
    "        \"accuracy\": best_acc,\n",
    "        \"f1\": f1_score(labels, preds, average=\"macro\"),\n",
    "        \"precision\": precision_score(labels, preds, average=\"macro\"),\n",
    "        \"recall\": recall_score(labels, preds, average=\"macro\"),\n",
    "        \"average_precision\": average_precision_score(labels, scores)\n",
    "    }\n",
    "\n",
    "\n",
    "def eval_pair_task(model, path_list):\n",
    "    model.eval()\n",
    "    print(' ✅ eval_pair_task')\n",
    "    for path in path_list:\n",
    "        print(path)\n",
    "        eval_dataset = PairDataset(path)\n",
    "        eval_loader = DataLoader(\n",
    "            eval_dataset,\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "            collate_fn=lambda x: collate_fn(x, tokenizer)\n",
    "        )\n",
    "        eval_pair(model, eval_loader)\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f6d226",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T08:33:32.718395Z",
     "iopub.status.busy": "2026-01-14T08:33:32.718149Z",
     "iopub.status.idle": "2026-01-14T08:33:32.735487Z",
     "shell.execute_reply": "2026-01-14T08:33:32.734836Z"
    },
    "papermill": {
     "duration": 0.049941,
     "end_time": "2026-01-14T08:33:32.736808",
     "exception": false,
     "start_time": "2026-01-14T08:33:32.686867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "def find_best_mapping(x, base_tokens, blending_special, base_special, best_one=True):\n",
    "    tmp_x = x.replace(blending_special, base_special)\n",
    "    if tmp_x in base_tokens:\n",
    "        return tmp_x, tmp_x\n",
    "    else:\n",
    "        if best_one:\n",
    "            best = None\n",
    "            best_dist = None\n",
    "            for y in base_tokens:\n",
    "                d = editdistance.eval(tmp_x, y)\n",
    "                if best is None or d < best_dist:\n",
    "                    best = y\n",
    "                    best_dist = d\n",
    "            return tmp_x, best\n",
    "        else:\n",
    "            token_and_distance = [(y, editdistance.eval(tmp_x, y)) for y in base_tokens]\n",
    "            min_distance = min(d for _, d in token_and_distance)\n",
    "            shortest_distance_tokens = [y for y, d in token_and_distance if d == min_distance]\n",
    "            return tmp_x, shortest_distance_tokens\n",
    "class CKALoss(nn.Module):\n",
    "    def __init__(self, eps ):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "    def forward(self, SH, TH): \n",
    "        dT = TH.size(-1)\n",
    "        dS = SH.size(-1)\n",
    "        SH = SH.view(-1,dS).to(SH.device,torch.float64)\n",
    "        TH = TH.view(-1,dT).to(SH.device,torch.float64)\n",
    "        \n",
    "        slen = SH.size(0)\n",
    "        SH = SH - SH.mean(0, keepdim=True)\n",
    "        TH = TH - TH.mean(0, keepdim=True)\n",
    "                \n",
    "        num = torch.norm(SH.t().matmul(TH),'fro')\n",
    "        den1 = torch.norm(SH.t().matmul(SH),'fro') + self.eps\n",
    "        den2 = torch.norm(TH.t().matmul(TH),'fro') + self.eps\n",
    "        \n",
    "        return 1 - num/torch.sqrt(den1*den2)\n",
    "def build_reciprocal_mapping_from_token_lists(\n",
    "    teacher_tokens, student_tokens,\n",
    "    teacher_special=\"<s>\", student_special=\"[CLS]\"\n",
    "):\n",
    "    teacher_to_student = align_tokens(teacher_tokens, student_tokens, teacher_special, student_special)\n",
    "    student_to_teacher = align_tokens(student_tokens, teacher_tokens, student_special, teacher_special)\n",
    "\n",
    "    reciprocal_mapping = {}\n",
    "    for t, s in teacher_to_student.items():\n",
    "        if s in student_to_teacher and student_to_teacher[s] == t:\n",
    "            reciprocal_mapping[t] = s\n",
    "    return reciprocal_mapping\n",
    "\n",
    "def filter_mapping_top_k(teacher_tokens, importance_vec, reciprocal_mapping, k):\n",
    "    if len(reciprocal_mapping) == 0:\n",
    "        return {}\n",
    "\n",
    "    token_scores = {}\n",
    "    for idx, tok in enumerate(teacher_tokens):\n",
    "        if tok in reciprocal_mapping:\n",
    "            score = importance_vec[idx].item()\n",
    "            if tok not in token_scores or score > token_scores[tok]:\n",
    "                token_scores[tok] = score\n",
    "\n",
    "    if len(token_scores) == 0:\n",
    "        return {}\n",
    "\n",
    "    k = max(1, min(k, len(token_scores)))\n",
    "    top_tokens = sorted(token_scores.items(), key=lambda x: x[1], reverse=True)[:k]\n",
    "    allowed = {tok for tok, _ in top_tokens}\n",
    "\n",
    "    filtered = {t: s for t, s in reciprocal_mapping.items() if t in allowed}\n",
    "    return filtered\n",
    "\n",
    "def get_indices_from_mapping_tokens(teacher_tokens, student_tokens, reciprocal_mapping):\n",
    "    if len(reciprocal_mapping) == 0:\n",
    "        return [], []\n",
    "\n",
    "    teacher_indices = [idx for idx, tok in enumerate(teacher_tokens) if tok in reciprocal_mapping]\n",
    "\n",
    "    mapped_student_tokens = set(reciprocal_mapping.values())\n",
    "    student_indices = [idx for idx, tok in enumerate(student_tokens) if tok in mapped_student_tokens]\n",
    "\n",
    "    return teacher_indices, student_indices\n",
    "\n",
    "def align_indices_by_mapping(teacher_indices, student_indices, reciprocal_top, teacher_tokens, student_tokens):\n",
    "    aligned_teacher = []\n",
    "    aligned_student = []\n",
    "\n",
    "    s2t = {v:k for k,v in reciprocal_top.items()}\n",
    "\n",
    "    for t_idx in teacher_indices:\n",
    "        t_tok = teacher_tokens[t_idx]\n",
    "        if t_tok not in reciprocal_top:\n",
    "            continue\n",
    "        s_tok = reciprocal_top[t_tok]\n",
    "        for idx_s, tok_s in enumerate(student_tokens):\n",
    "            if tok_s == s_tok:\n",
    "                aligned_teacher.append(t_idx)\n",
    "                aligned_student.append(idx_s)\n",
    "                break\n",
    "\n",
    "    return aligned_teacher, aligned_student\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18317ee8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T08:33:32.798082Z",
     "iopub.status.busy": "2026-01-14T08:33:32.797822Z",
     "iopub.status.idle": "2026-01-14T08:33:32.815507Z",
     "shell.execute_reply": "2026-01-14T08:33:32.814759Z"
    },
    "papermill": {
     "duration": 0.050141,
     "end_time": "2026-01-14T08:33:32.816927",
     "exception": false,
     "start_time": "2026-01-14T08:33:32.766786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- Edit distance backend ---\n",
    "try:\n",
    "    import Levenshtein as _Lev\n",
    "    def _edit_dist(a: str, b: str) -> int:\n",
    "        return _Lev.distance(a, b)\n",
    "except Exception:\n",
    "    def _edit_dist(a: str, b: str) -> int:\n",
    "        # pure-python Levenshtein distance\n",
    "        if a == b:\n",
    "            return 0\n",
    "        if len(a) == 0:\n",
    "            return len(b)\n",
    "        if len(b) == 0:\n",
    "            return len(a)\n",
    "        if len(a) < len(b):\n",
    "            a, b = b, a\n",
    "        prev = list(range(len(b) + 1))\n",
    "        for i, ca in enumerate(a, start=1):\n",
    "            cur = [i]\n",
    "            for j, cb in enumerate(b, start=1):\n",
    "                ins = cur[j-1] + 1\n",
    "                dele = prev[j] + 1\n",
    "                sub = prev[j-1] + (ca != cb)\n",
    "                cur.append(min(ins, dele, sub))\n",
    "            prev = cur\n",
    "        return prev[-1]\n",
    "\n",
    "def _clean_tok(t: str) -> str:\n",
    "    if t is None:\n",
    "        return \"\"\n",
    "    # SentencePiece / GPT / WordPiece cleanup\n",
    "    t = t.replace(\"▁\", \"\").replace(\"Ġ\", \"\")\n",
    "    if t.startswith(\"##\"):\n",
    "        t = t[2:]\n",
    "    return t.strip().lower()\n",
    "\n",
    "def compute_token_importance(attention_weights: torch.Tensor) -> torch.Tensor:\n",
    "    '''\n",
    "    attention_weights: [H, L, L] or [L, L]\n",
    "    Importance = column-sum of avg attention -> softmax -> probs over tokens.\n",
    "    '''\n",
    "    if attention_weights.dim() == 3:\n",
    "        avg_att = attention_weights.mean(dim=0)   # [L, L]\n",
    "    else:\n",
    "        avg_att = attention_weights               # [L, L]\n",
    "    scores = avg_att.sum(dim=0)                   # [L]\n",
    "    return torch.softmax(scores, dim=-1)\n",
    "\n",
    "def align_tokens(teacher_tokens, student_tokens, teacher_special=\"<s>\", student_special=\"[CLS]\"):\n",
    "    '''\n",
    "    Return a dict mapping teacher_token_string -> student_token_string (best match).\n",
    "    Used by build_reciprocal_mapping_from_token_lists() in compute_att_loss_2.\n",
    "    '''\n",
    "    teacher_to_student = {}\n",
    "    if (not teacher_tokens) or (not student_tokens):\n",
    "        return teacher_to_student\n",
    "\n",
    "    # Map special token if both exist\n",
    "    if teacher_special in teacher_tokens and student_special in student_tokens:\n",
    "        teacher_to_student[teacher_special] = student_special\n",
    "\n",
    "    student_set = set(student_tokens)\n",
    "\n",
    "    # Pre-clean student tokens once\n",
    "    stu_clean = [(s, _clean_tok(s)) for s in student_tokens if s != student_special]\n",
    "\n",
    "    for t in teacher_tokens:\n",
    "        if t == teacher_special:\n",
    "            continue\n",
    "\n",
    "        # quick exact match after special replacement\n",
    "        tmp_t = t.replace(teacher_special, student_special)\n",
    "        if tmp_t in student_set and tmp_t != student_special:\n",
    "            teacher_to_student[t] = tmp_t\n",
    "            continue\n",
    "\n",
    "        t_clean = _clean_tok(tmp_t)\n",
    "        if t_clean == \"\":\n",
    "            continue\n",
    "\n",
    "        best_s, best_d = None, 10**9\n",
    "        for s, s_clean in stu_clean:\n",
    "            if t_clean == s_clean:\n",
    "                best_s, best_d = s, 0\n",
    "                break\n",
    "            d = _edit_dist(t_clean, s_clean)\n",
    "            if d < best_d:\n",
    "                best_s, best_d = s, d\n",
    "\n",
    "        if best_s is not None:\n",
    "            teacher_to_student[t] = best_s\n",
    "\n",
    "    return teacher_to_student\n",
    "\n",
    "# --- Matryoshka (nested-prefix) cosine distillation loss ---\n",
    "def matryoshka_prefix_cosine_loss(student_emb: torch.Tensor,\n",
    "                                  teacher_emb: torch.Tensor,\n",
    "                                  dims=(128, 256, 512),\n",
    "                                  eps: float = 1e-8) -> torch.Tensor:\n",
    "    '''\n",
    "    student_emb, teacher_emb: [B, D] (same D)\n",
    "    Loss = average over d in dims plus full D of (1 - cosine(student[:d], teacher[:d])).\n",
    "    '''\n",
    "    assert student_emb.dim() == 2 and teacher_emb.dim() == 2\n",
    "    B, D = student_emb.shape\n",
    "    assert teacher_emb.shape == (B, D)\n",
    "\n",
    "    dims_list = [int(d) for d in dims if (d is not None and int(d) > 0 and int(d) <= D)]\n",
    "    if D not in dims_list:\n",
    "        dims_list.append(D)\n",
    "    dims_list = sorted(set(dims_list))\n",
    "\n",
    "    total = 0.0\n",
    "    for d in dims_list:\n",
    "        s = student_emb[:, :d].float()\n",
    "        t = teacher_emb[:, :d].float()\n",
    "        s = s / (s.norm(dim=-1, keepdim=True) + eps)\n",
    "        t = t / (t.norm(dim=-1, keepdim=True) + eps)\n",
    "        total = total + (1.0 - (s * t).sum(dim=-1)).mean()\n",
    "    return total / len(dims_list)\n",
    "\n",
    "def extract_teacher_sentence_embedding(T_last: torch.Tensor,\n",
    "                                      input_ids: torch.Tensor,\n",
    "                                      attention_mask: torch.Tensor,\n",
    "                                      tok_teacher,\n",
    "                                      embed_token: str = None):\n",
    "    '''\n",
    "    Returns teacher sentence embedding [B, d_t].\n",
    "    Priority:\n",
    "      1) If embed_token is provided and present in the sequence: use its hidden state.\n",
    "      2) Else: mean pooling.\n",
    "    This supports LLM2Vec-style embedding tokens if they exist.\n",
    "    '''\n",
    "    if embed_token is not None:\n",
    "        try:\n",
    "            embed_id = tok_teacher.convert_tokens_to_ids(embed_token)\n",
    "            # Guard: only use if the token is really in vocab (avoid unk collisions)\n",
    "            try:\n",
    "                if embed_token not in tok_teacher.get_vocab():\n",
    "                    embed_id = None\n",
    "            except Exception:\n",
    "                pass\n",
    "        except Exception:\n",
    "            embed_id = None\n",
    "\n",
    "        if embed_id is not None:\n",
    "            m = (input_ids == embed_id)  # [B, L]\n",
    "            if m.any():\n",
    "                idx = m.float().argmax(dim=1)  # [B]\n",
    "                has_any = m.any(dim=1)         # [B]\n",
    "                out = T_last[:, 0, :].clone()\n",
    "                b_idx = torch.arange(T_last.size(0), device=T_last.device)\n",
    "                out[has_any] = T_last[b_idx[has_any], idx[has_any], :]\n",
    "                return out\n",
    "\n",
    "    # Fallback: mean pooling\n",
    "    mask = attention_mask.unsqueeze(-1).type_as(T_last)\n",
    "    summed = (T_last * mask).sum(dim=1)\n",
    "    counts = mask.sum(dim=1).clamp(min=1e-9)\n",
    "    return summed / counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c66a6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T08:33:32.877737Z",
     "iopub.status.busy": "2026-01-14T08:33:32.877496Z",
     "iopub.status.idle": "2026-01-14T08:33:32.882022Z",
     "shell.execute_reply": "2026-01-14T08:33:32.881245Z"
    },
    "papermill": {
     "duration": 0.036382,
     "end_time": "2026-01-14T08:33:32.883540",
     "exception": false,
     "start_time": "2026-01-14T08:33:32.847158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_cls_tasks = [('/kaggle/input/multitask-data/multi-data/banking_train.csv', \n",
    "                   '/kaggle/input/multitask-data/multi-data/banking77_validation.csv'),\n",
    "                  ('/kaggle/input/multitask-data/multi-data/emotion_train.csv', \n",
    "                   '/kaggle/input/multitask-data/multi-data/emotion_validation.csv'), \n",
    "                  ('/kaggle/input/multitask-data/multi-data/tweet_train.csv', \n",
    "                   '/kaggle/input/multitask-data/multi-data/tweet_validation.csv')]\n",
    "\n",
    "eval_sts_tasks = ['/kaggle/input/multitask-data/multi-data/sick_validation.csv', \n",
    "                  '/kaggle/input/multitask-data/multi-data/sts12_validation.csv', \n",
    "                  '/kaggle/input/multitask-data/multi-data/stsb_validation.csv']\n",
    "\n",
    "eval_pair_tasks = ['/kaggle/input/multitask-data/multi-data/mrpc_validation.csv', \n",
    "                   '/kaggle/input/multitask-data/multi-data/scitail_validation.csv', \n",
    "                   '/kaggle/input/multitask-data/multi-data/wic_validation.csv']\n",
    "test_cls_tasks = [('/kaggle/input/multitask-data/multi-data/banking_train.csv', \n",
    "                   '/kaggle/input/multitask-data/multi-data/banking77_test.csv'),\n",
    "                  ('/kaggle/input/multitask-data/multi-data/emotion_train.csv', \n",
    "                   '/kaggle/input/multitask-data/multi-data/emotion_test.csv'), \n",
    "                  ('/kaggle/input/multitask-data/multi-data/tweet_train.csv', \n",
    "                   '/kaggle/input/multitask-data/multi-data/tweet_test.csv')]\n",
    "\n",
    "test_sts_tasks = ['/kaggle/input/multitask-data/multi-data/sick_test.csv', \n",
    "                  '/kaggle/input/multitask-data/multi-data/sts12_test.csv', \n",
    "                  '/kaggle/input/multitask-data/multi-data/stsb_test.csv']\n",
    "\n",
    "test_pair_tasks = ['/kaggle/input/multitask-data/multi-data/mrpc_test.csv', \n",
    "                   '/kaggle/input/multitask-data/multi-data/scitail_test.csv', \n",
    "                   '/kaggle/input/multitask-data/multi-data/wic_test.csv']\n",
    "\n",
    "# model_student.to(\"cuda\")\n",
    "# eval_classification_task(model_student, test_cls_tasks)\n",
    "# eval_pair_task(model_student, test_pair_tasks)\n",
    "# eval_sts_task(model_student, test_sts_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3e53d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T08:33:32.944969Z",
     "iopub.status.busy": "2026-01-14T08:33:32.944356Z",
     "iopub.status.idle": "2026-01-14T08:33:32.948689Z",
     "shell.execute_reply": "2026-01-14T08:33:32.948141Z"
    },
    "papermill": {
     "duration": 0.035984,
     "end_time": "2026-01-14T08:33:32.949998",
     "exception": false,
     "start_time": "2026-01-14T08:33:32.914014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "def last_token_pool(last_hidden_states: Tensor,\n",
    "                 attention_mask: Tensor) -> Tensor:\n",
    "    left_padding = (attention_mask[:, -1].sum() == attention_mask.shape[0])\n",
    "    if left_padding:\n",
    "        return last_hidden_states[:, -1]\n",
    "    else:\n",
    "        sequence_lengths = attention_mask.sum(dim=1) - 1\n",
    "        batch_size = last_hidden_states.shape[0]\n",
    "        return last_hidden_states[torch.arange(batch_size, device=last_hidden_states.device), sequence_lengths]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e397dfce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T08:33:33.010329Z",
     "iopub.status.busy": "2026-01-14T08:33:33.009824Z",
     "iopub.status.idle": "2026-01-14T08:33:40.968845Z",
     "shell.execute_reply": "2026-01-14T08:33:40.968078Z"
    },
    "papermill": {
     "duration": 7.991278,
     "end_time": "2026-01-14T08:33:40.970561",
     "exception": false,
     "start_time": "2026-01-14T08:33:32.979283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_f1_macro = -1.0\n",
    "all_preds, all_labels = [], []\n",
    "total_loss = 0.0\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "num_steps = len(train_loader)\n",
    "total_traning_steps = num_steps * epochs\n",
    "warmup_ratio = 0.1\n",
    "\n",
    "def pick_devices():\n",
    "    if torch.cuda.device_count() >= 2:\n",
    "        dev_s = torch.device(\"cuda:0\")  # student\n",
    "        dev_t = torch.device(\"cuda:1\")  # teacher\n",
    "    elif torch.cuda.is_available():\n",
    "        print(\"[WARN] Only 1 GPU available -> both on cuda:0\")\n",
    "        dev_s = dev_t = torch.device(\"cuda:0\")\n",
    "    else:\n",
    "        print(\"[WARN] No GPU -> CPU\")\n",
    "        dev_s = dev_t = torch.device(\"cpu\")\n",
    "    return dev_s, dev_t\n",
    "\n",
    "device_s, device_t = pick_devices()\n",
    "\n",
    "model_student.to(device_s)\n",
    "model_teacher.to(device_t)\n",
    "model_teacher.eval()\n",
    "for p in model_teacher.parameters():\n",
    "    p.requires_grad_(False)\n",
    "\n",
    "proj_s2t = None\n",
    "proj_t2s = None\n",
    "\n",
    "optimizer = optim.AdamW(model_student.parameters(), lr=LR)\n",
    "scaler = GradScaler(enabled=torch.cuda.is_available())\n",
    "scheduler = get_scheduler(\n",
    "    name='cosine_with_min_lr',\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=int(total_traning_steps * warmup_ratio),\n",
    "    # num_warmup_steps=1,\n",
    "    num_training_steps=total_traning_steps,\n",
    "    scheduler_specific_kwargs={'min_lr': 2e-6}\n",
    ")\n",
    "if save_dir:\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "n_items = 0\n",
    "use_task_loss = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63dfa8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T08:33:41.092714Z",
     "iopub.status.busy": "2026-01-14T08:33:41.091724Z",
     "iopub.status.idle": "2026-01-14T08:33:41.097998Z",
     "shell.execute_reply": "2026-01-14T08:33:41.097263Z"
    },
    "papermill": {
     "duration": 0.03854,
     "end_time": "2026-01-14T08:33:41.099359",
     "exception": false,
     "start_time": "2026-01-14T08:33:41.060819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TUNING KNOBS\n",
    "# Sentence embedding pooling for student (SimCSE + MRL use this)\n",
    "# \"cls\" = token at position 0; \"mean\" = masked mean pooling\n",
    "student_pool = \"mean\"   # {\"cls\",\"mean\"}\n",
    "\n",
    "# Overall weights\n",
    "w_task   = 0.5     # SimCSE InfoNCE weight\n",
    "alpha_kd = 0.5     # total KD weight (applies to alpha_attn*att_loss + beta_mrl*mrl_loss)\n",
    "\n",
    "# ---- MRL (Matryoshka) ----\n",
    "beta_mrl_max   = 1.0      # final MRL weight inside KD\n",
    "mrl_start      = 0        # start ramp at this global_step\n",
    "mrl_ramp       = 1000     # steps to ramp from 0 -> beta_mrl_max\n",
    "mrl_weight_mode = \"inverse_sqrt\"  # {\"uniform\",\"inverse_sqrt\",\"inverse\",\"log\"}\n",
    "\n",
    "# Matryoshka prefix dimensions (filtered by hidden size automatically)\n",
    "# d_s is defined later after models are loaded; we set dims after d_s is known.\n",
    "\n",
    "# ---- CKA / IRA (attention alignment) ----\n",
    "alpha_attn_max = 0.02     # final attention weight inside KD (keep small)\n",
    "att_start      = 1500     # start ramp for attention loss\n",
    "att_ramp       = 2500     # steps to ramp from 0 -> alpha_attn_max\n",
    "att_every      = 4        # compute attention loss every N steps (reduce overhead)\n",
    "top_frac       = 0.25     # fraction of mapped tokens to align (0.2~0.33 stable)\n",
    "min_tokens     = 2        # minimum aligned tokens required to compute CKA\n",
    "k_ira          = 1        # last-k layers for IRA/CKA\n",
    "\n",
    "def ramp(step: int, start: int, ramp_steps: int) -> float:\n",
    "    if step < start:\n",
    "        return 0.0\n",
    "    if ramp_steps <= 0:\n",
    "        return 1.0\n",
    "    return min(1.0, (step - start) / float(ramp_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73b22c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T08:33:41.161686Z",
     "iopub.status.busy": "2026-01-14T08:33:41.161208Z",
     "iopub.status.idle": "2026-01-14T08:33:41.223283Z",
     "shell.execute_reply": "2026-01-14T08:33:41.222740Z"
    },
    "papermill": {
     "duration": 0.095172,
     "end_time": "2026-01-14T08:33:41.224635",
     "exception": false,
     "start_time": "2026-01-14T08:33:41.129463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# KD UTILITIES: token alignment, CKA, MRL, teacher embedding\n",
    "\n",
    "# pooling\n",
    "def mean_pooling(last_hidden_state: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "    mask = attention_mask.unsqueeze(-1).type_as(last_hidden_state)\n",
    "    summed = (last_hidden_state * mask).sum(dim=1)\n",
    "    counts = mask.sum(dim=1).clamp(min=1e-9)\n",
    "    return summed / counts\n",
    "\n",
    "def get_student_sentence_emb(last_hidden: torch.Tensor, att_mask: torch.Tensor, mode: str) -> torch.Tensor:\n",
    "    if mode == \"mean\":\n",
    "        return mean_pooling(last_hidden, att_mask)\n",
    "    return last_hidden[:, 0, :]  # \"cls\"\n",
    "\n",
    "# robust edit distance (optional)\n",
    "try:\n",
    "    import Levenshtein as _Lev\n",
    "    def _edit_dist(a: str, b: str) -> int:\n",
    "        return _Lev.distance(a, b)\n",
    "except Exception:\n",
    "    def _edit_dist(a: str, b: str) -> int:\n",
    "        # pure python levenshtein\n",
    "        if a == b:\n",
    "            return 0\n",
    "        if len(a) == 0:\n",
    "            return len(b)\n",
    "        if len(b) == 0:\n",
    "            return len(a)\n",
    "        if len(a) < len(b):\n",
    "            a, b = b, a\n",
    "        prev = list(range(len(b) + 1))\n",
    "        for i, ca in enumerate(a, start=1):\n",
    "            cur = [i]\n",
    "            for j, cb in enumerate(b, start=1):\n",
    "                ins = cur[j-1] + 1\n",
    "                dele = prev[j] + 1\n",
    "                sub = prev[j-1] + (ca != cb)\n",
    "                cur.append(min(ins, dele, sub))\n",
    "            prev = cur\n",
    "        return prev[-1]\n",
    "\n",
    "def _clean_tok(t: str) -> str:\n",
    "    if t is None:\n",
    "        return \"\"\n",
    "    t = t.replace(\"▁\", \"\").replace(\"Ġ\", \"\")\n",
    "    if t.startswith(\"##\"):\n",
    "        t = t[2:]\n",
    "    return t.strip().lower()\n",
    "\n",
    "# token importance (FIXED SIGNATURE)\n",
    "def compute_token_importance(attention_weights: torch.Tensor, tokens=None) -> torch.Tensor:\n",
    "    '''\n",
    "    attention_weights: [H, L, L] or [L, L]\n",
    "    tokens: optional list[str] of length L (may include special tokens)\n",
    "    Returns: probs [L]\n",
    "    '''\n",
    "    if attention_weights.dim() == 3:\n",
    "        avg_att = attention_weights.mean(dim=0)   # [L, L]\n",
    "    else:\n",
    "        avg_att = attention_weights               # [L, L]\n",
    "    scores = avg_att.sum(dim=0)                   # [L]\n",
    "\n",
    "    # Downweight obvious special tokens if tokens are provided\n",
    "    if tokens is not None and isinstance(tokens, (list, tuple)) and len(tokens) == scores.numel():\n",
    "        special = {\n",
    "            \"[PAD]\", \"<pad>\", \"</s>\", \"<s>\", \"[CLS]\", \"[SEP]\", \"[UNK]\",\n",
    "            \"<|pad|>\", \"<|endoftext|>\", \"<|eos|>\", \"<|bos|>\", \"<|embed|>\"\n",
    "        }\n",
    "        scores = scores.clone()\n",
    "        bad = [i for i,t in enumerate(tokens) if t in special]\n",
    "        if 0 < len(bad) < scores.numel():\n",
    "            scores[bad] = -1e9\n",
    "\n",
    "    return torch.softmax(scores, dim=-1)\n",
    "\n",
    "# token alignment\n",
    "def align_tokens(teacher_tokens, student_tokens, teacher_special=\"<s>\", student_special=\"[CLS]\"):\n",
    "    '''\n",
    "    Map each teacher token string -> closest student token string.\n",
    "    Used by IRA/CKA when teacher/student tokenizers differ.\n",
    "    '''\n",
    "    out = {}\n",
    "    if (not teacher_tokens) or (not student_tokens):\n",
    "        return out\n",
    "\n",
    "    student_set = set(student_tokens)\n",
    "\n",
    "    # special token mapping\n",
    "    if teacher_special in teacher_tokens and student_special in student_tokens:\n",
    "        out[teacher_special] = student_special\n",
    "\n",
    "    stu_clean = [(s, _clean_tok(s)) for s in student_tokens if s != student_special]\n",
    "\n",
    "    for t in teacher_tokens:\n",
    "        if t == teacher_special:\n",
    "            continue\n",
    "        tmp_t = t.replace(teacher_special, student_special)\n",
    "        if tmp_t in student_set and tmp_t != student_special:\n",
    "            out[t] = tmp_t\n",
    "            continue\n",
    "\n",
    "        t_clean = _clean_tok(tmp_t)\n",
    "        if t_clean == \"\":\n",
    "            continue\n",
    "\n",
    "        best_s, best_d = None, 10**9\n",
    "        for s, s_clean in stu_clean:\n",
    "            if t_clean == s_clean:\n",
    "                best_s, best_d = s, 0\n",
    "                break\n",
    "            d = _edit_dist(t_clean, s_clean)\n",
    "            if d < best_d:\n",
    "                best_s, best_d = s, d\n",
    "        if best_s is not None:\n",
    "            out[t] = best_s\n",
    "\n",
    "    return out\n",
    "\n",
    "def build_reciprocal_mapping_from_token_lists(teacher_tokens, student_tokens,\n",
    "                                              teacher_special=\"<s>\", student_special=\"[CLS]\"):\n",
    "    teacher_to_student = align_tokens(teacher_tokens, student_tokens, teacher_special, student_special)\n",
    "    student_to_teacher = align_tokens(student_tokens, teacher_tokens, student_special, teacher_special)\n",
    "\n",
    "    reciprocal = {}\n",
    "    for t, s in teacher_to_student.items():\n",
    "        if s in student_to_teacher and student_to_teacher[s] == t:\n",
    "            reciprocal[t] = s\n",
    "    return reciprocal\n",
    "\n",
    "# Linear CKA (stable)\n",
    "class LinearCKALoss(nn.Module):\n",
    "    '''\n",
    "    Linear CKA: ||X^T Y||_F^2 / (||X^T X||_F * ||Y^T Y||_F)\n",
    "    Loss = 1 - CKA in [0,1] (approximately).\n",
    "    '''\n",
    "    def __init__(self, eps: float = 1e-8):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, X: torch.Tensor, Y: torch.Tensor) -> torch.Tensor:\n",
    "        # X,Y: [N, D]\n",
    "        X = X.float()\n",
    "        Y = Y.float()\n",
    "        X = X - X.mean(dim=0, keepdim=True)\n",
    "        Y = Y - Y.mean(dim=0, keepdim=True)\n",
    "\n",
    "        XT_Y = X.t().matmul(Y)\n",
    "        XT_X = X.t().matmul(X)\n",
    "        YT_Y = Y.t().matmul(Y)\n",
    "\n",
    "        num = (XT_Y ** 2).sum()  # ||X^T Y||_F^2\n",
    "        den = torch.norm(XT_X, p=\"fro\") * torch.norm(YT_Y, p=\"fro\")\n",
    "        return 1.0 - (num / (den + self.eps))\n",
    "\n",
    "# IRA/CKA attention alignment\n",
    "def _build_span_overlap_matrix(offsets_tea, offsets_stu, L_t: int, L_s: int, device, eps: float = 1e-12):\n",
    "    if offsets_tea is None or offsets_stu is None:\n",
    "        return None, 0.0, 0.0\n",
    "\n",
    "    # Ensure CPU lists for fast monotonic scan\n",
    "    if torch.is_tensor(offsets_tea):\n",
    "        ot = offsets_tea[:L_t].detach().cpu().tolist()\n",
    "    else:\n",
    "        ot = list(offsets_tea)[:L_t]\n",
    "    if torch.is_tensor(offsets_stu):\n",
    "        os_ = offsets_stu[:L_s].detach().cpu().tolist()\n",
    "    else:\n",
    "        os_ = list(offsets_stu)[:L_s]\n",
    "\n",
    "    A = torch.zeros((L_s, L_t), device=device, dtype=torch.float32)\n",
    "\n",
    "    i = 0  # teacher\n",
    "    j = 0  # student\n",
    "    # Monotonic two-pointer overlap fill\n",
    "    while i < L_t and j < L_s:\n",
    "        a, b = ot[i]\n",
    "        c, d = os_[j]\n",
    "\n",
    "        # skip zero-length spans (special tokens)\n",
    "        if b <= a:\n",
    "            i += 1\n",
    "            continue\n",
    "        if d <= c:\n",
    "            j += 1\n",
    "            continue\n",
    "\n",
    "        if b <= c:\n",
    "            i += 1\n",
    "            continue\n",
    "        if d <= a:\n",
    "            j += 1\n",
    "            continue\n",
    "\n",
    "        overlap = min(b, d) - max(a, c)\n",
    "        if overlap > 0:\n",
    "            A[j, i] = float(overlap)\n",
    "\n",
    "        # advance whichever span ends first\n",
    "        if b < d:\n",
    "            i += 1\n",
    "        elif d < b:\n",
    "            j += 1\n",
    "        else:\n",
    "            i += 1\n",
    "            j += 1\n",
    "\n",
    "    row_sum = A.sum(dim=1, keepdim=True)\n",
    "    A = A / row_sum.clamp_min(eps)\n",
    "\n",
    "    coverage_s = float((row_sum.squeeze(1) > 0).float().mean().item())\n",
    "    coverage_t = float((A.sum(dim=0) > 0).float().mean().item())\n",
    "    return A, coverage_s, coverage_t\n",
    "\n",
    "\n",
    "def _project_teacher_attention_to_student(Attn_t: torch.Tensor, A: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Project teacher attention into student token space using A.\n",
    "\n",
    "    Attn_t: [H, N, N]\n",
    "    A:      [M, N] (row-normalized)\n",
    "    Returns:\n",
    "        Attn_t_proj: [H, M, M] where Attn_t_proj = A @ Attn_t @ A^T\n",
    "    \"\"\"\n",
    "    # left: (M,N) x (H,N,N) -> (H,M,N)\n",
    "    tmp = torch.einsum(\"mn,hnk->hmk\", A, Attn_t)\n",
    "    # right: (H,M,N) x (N,M) -> (H,M,M)\n",
    "    return torch.einsum(\"hmn,nk->hmk\", tmp, A.transpose(0, 1))\n",
    "\n",
    "# Gram centering utilities\n",
    "def _center_gram(K: torch.Tensor, unbiased: bool = False) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Center a Gram matrix K in RKHS sense.\n",
    "    K: [N, N]\n",
    "    \"\"\"\n",
    "    if not unbiased:\n",
    "        mean_row = K.mean(dim=0, keepdim=True)\n",
    "        mean_col = K.mean(dim=1, keepdim=True)\n",
    "        mean_all = K.mean()\n",
    "        return K - mean_row - mean_col + mean_all\n",
    "\n",
    "    # Unbiased-ish centering for small N (often reduces bias).\n",
    "    # Works well when N is not huge.\n",
    "    N = K.size(0)\n",
    "    if N <= 2:\n",
    "        return K - K.mean()\n",
    "\n",
    "    K = K.clone()\n",
    "    K.fill_diagonal_(0)\n",
    "    means = K.sum(dim=0) / (N - 2)\n",
    "    means = means - means.sum() / (2 * (N - 1))\n",
    "    K = K - means.unsqueeze(0) - means.unsqueeze(1)\n",
    "    K.fill_diagonal_(0)\n",
    "    return K\n",
    "\n",
    "\n",
    "# Attention transforms\n",
    "def _remove_diag_and_renorm(att: torch.Tensor, eps: float) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    att: [H, N, N] or [H, N, D] (diagonal removal only if last dim == N)\n",
    "    \"\"\"\n",
    "    H, N, D = att.shape\n",
    "    if D != N:\n",
    "        return att\n",
    "\n",
    "    eye = torch.eye(N, device=att.device, dtype=att.dtype).unsqueeze(0)  # [1,N,N]\n",
    "    att = att * (1.0 - eye)  # zero diagonal\n",
    "    att = att / (att.sum(dim=-1, keepdim=True).clamp_min(eps))\n",
    "    return att\n",
    "\n",
    "\n",
    "def _attn_transform(\n",
    "    att: torch.Tensor,\n",
    "    transform: str = \"clr\",     # \"none\" | \"sqrt\" | \"log\" | \"clr\"\n",
    "    eps: float = 1e-8,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Transform attention distributions to make them more comparable for CKA.\n",
    "\n",
    "    att: [H, N, D], rows are distributions over keys (D).\n",
    "    \"\"\"\n",
    "    att = att.clamp_min(eps)\n",
    "\n",
    "    if transform == \"none\":\n",
    "        return att\n",
    "    if transform == \"sqrt\":\n",
    "        return torch.sqrt(att)\n",
    "    if transform == \"log\":\n",
    "        return torch.log(att)\n",
    "    if transform == \"clr\":\n",
    "        # centered log-ratio: log(p) - mean(log(p)) per row\n",
    "        logp = torch.log(att)\n",
    "        return logp - logp.mean(dim=-1, keepdim=True)\n",
    "\n",
    "    raise ValueError(f\"Unknown transform={transform}\")\n",
    "\n",
    "\n",
    "def _row_entropy(att: torch.Tensor, eps: float = 1e-8) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute entropy per query row from attention distribution.\n",
    "    att: [N, D] (already row-normalized probs)\n",
    "    returns: [N]\n",
    "    \"\"\"\n",
    "    p = att.clamp_min(eps)\n",
    "    return -(p * torch.log(p)).sum(dim=-1)\n",
    "\n",
    "\n",
    "def _select_queries_by_focus(\n",
    "    att_mean: torch.Tensor,        # [N, N] mean over heads for a square attn map\n",
    "    max_q: int,\n",
    "    eps: float = 1e-8\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Select query indices using focus score = 1 - normalized_entropy.\n",
    "    If max_q >= N => all.\n",
    "    \"\"\"\n",
    "    N = att_mean.size(0)\n",
    "    if max_q is None or max_q >= N:\n",
    "        return torch.arange(N, device=att_mean.device)\n",
    "\n",
    "    # Ensure row-normalized\n",
    "    A = att_mean.clamp_min(eps)\n",
    "    A = A / A.sum(dim=-1, keepdim=True).clamp_min(eps)\n",
    "\n",
    "    ent = _row_entropy(A, eps=eps)  # [N]\n",
    "    ent_norm = ent / math.log(float(N) + 1e-12)  # in [0,1] roughly\n",
    "    focus = 1.0 - ent_norm  # higher = sharper/more informative\n",
    "\n",
    "    top = torch.topk(focus, k=max_q, largest=True).indices\n",
    "    return torch.sort(top).values\n",
    "\n",
    "\n",
    "# Multi-head CKA\n",
    "class MultiHeadCKALoss(nn.Module):\n",
    "    \"\"\"\n",
    "    CKA computed in Gram space using multi-head kernel aggregation:\n",
    "\n",
    "        K = (1/H) * sum_h (X_h X_h^T)\n",
    "        L = (1/H')* sum_h (Y_h Y_h^T)\n",
    "\n",
    "    Then:\n",
    "        CKA(K,L) = <Kc, Lc>_F / (||Kc||_F ||Lc||_F)\n",
    "        loss = 1 - CKA\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        eps: float = 1e-8,\n",
    "        unbiased_center: bool = False,\n",
    "        transform: str = \"clr\",     # good default for attention probs\n",
    "        remove_diag: bool = True,\n",
    "        use_fp64: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.unbiased_center = unbiased_center\n",
    "        self.transform = transform\n",
    "        self.remove_diag = remove_diag\n",
    "        self.use_fp64 = use_fp64\n",
    "\n",
    "    def _multihead_linear_gram(self, att: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        att: [H, N, D] (D typically == N after token selection)\n",
    "        returns: [N, N] Gram over queries\n",
    "        \"\"\"\n",
    "        if self.remove_diag:\n",
    "            att = _remove_diag_and_renorm(att, eps=self.eps)\n",
    "\n",
    "        # Row-normalize (important if attentions are not perfectly normalized after slicing)\n",
    "        att = att.clamp_min(self.eps)\n",
    "        att = att / att.sum(dim=-1, keepdim=True).clamp_min(self.eps)\n",
    "\n",
    "        # Transform in probability space (CLR/log/sqrt)\n",
    "        att = _attn_transform(att, transform=self.transform, eps=self.eps)\n",
    "\n",
    "        # Use fp64 for stability if desired\n",
    "        if self.use_fp64:\n",
    "            att = att.double()\n",
    "\n",
    "        # Compute K[n,m] = (1/H) * sum_h sum_k att[h,n,k] * att[h,m,k]\n",
    "        # einsum does: sum over h,k\n",
    "        K = torch.einsum(\"hnk,hmk->nm\", att, att)\n",
    "        K = K / float(att.size(0))  # average over heads\n",
    "\n",
    "        # Back to fp32 for downstream\n",
    "        return K.float() if self.use_fp64 else K\n",
    "\n",
    "    def forward(self, att_s: torch.Tensor, att_t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        att_s: [Hs, N, D]\n",
    "        att_t: [Ht, N, D]\n",
    "        \"\"\"\n",
    "        N = att_s.size(1)\n",
    "        if N <= 1:\n",
    "            return torch.zeros((), device=att_s.device)\n",
    "\n",
    "        K = self._multihead_linear_gram(att_s)  # [N,N]\n",
    "        L = self._multihead_linear_gram(att_t)  # [N,N]\n",
    "\n",
    "        Kc = _center_gram(K, unbiased=self.unbiased_center)\n",
    "        Lc = _center_gram(L, unbiased=self.unbiased_center)\n",
    "\n",
    "        num = (Kc * Lc).sum()\n",
    "        den = torch.sqrt((Kc * Kc).sum() * (Lc * Lc).sum()).clamp_min(self.eps)\n",
    "\n",
    "        cka = (num / den).clamp(min=-1.0, max=1.0)\n",
    "        return 1.0 - cka\n",
    "\n",
    "\n",
    "def compute_att_loss_2(\n",
    "    teacher_atts, student_atts,\n",
    "    input_ids_tea, input_ids_stu,\n",
    "    attention_mask_tea, attention_mask_stu,\n",
    "    tok_teacher, tok_student,\n",
    "    k: int,\n",
    "    device,\n",
    "    teacher_special=\"<s>\",\n",
    "    student_special=\"[CLS]\",\n",
    "    top_frac: float = 0.25,\n",
    "    min_tokens: int = 2,\n",
    "    offset_mapping_tea=None,\n",
    "    offset_mapping_stu=None,\n",
    "    min_coverage: float = 0.30,\n",
    "    cka_transform: str = \"clr\",          # \"clr\" tends to beat plain linear on attention probs\n",
    "    cka_unbiased_center: bool = False,\n",
    "    cka_remove_diag: bool = True,\n",
    "    cka_use_fp64: bool = True,\n",
    "    query_sample: int = None,            # e.g. 96 or 128; None = use all\n",
    "):\n",
    "    \"\"\"\n",
    "    IRA/CKA attention alignment with Span-MinED (preferred) + MinED fallback.\n",
    "    This version uses MultiHeadCKA in Gram space (significantly stronger than\n",
    "    head-averaged LinearCKA with feature truncation).\n",
    "\n",
    "    Expected attn shapes per layer:\n",
    "      teacher_atts[layer] : [B, Ht, Lt, Lt]\n",
    "      student_atts[layer] : [B, Hs, Ls, Ls]\n",
    "    \"\"\"\n",
    "    cka = MultiHeadCKALoss(\n",
    "        eps=1e-8,\n",
    "        unbiased_center=cka_unbiased_center,\n",
    "        transform=cka_transform,\n",
    "        remove_diag=cka_remove_diag,\n",
    "        use_fp64=cka_use_fp64,\n",
    "    ).to(device)\n",
    "\n",
    "    # Use last-k layers\n",
    "    teacher_last_k = teacher_atts[-k:]\n",
    "    student_last_k = student_atts[-k:]\n",
    "\n",
    "    B = input_ids_tea.size(0)\n",
    "    att_loss_total = torch.zeros((), device=device)\n",
    "    n_terms = 0\n",
    "\n",
    "    for b in range(B):\n",
    "        Lt = int(attention_mask_tea[b].sum().item())\n",
    "        Ls = int(attention_mask_stu[b].sum().item())\n",
    "        if Lt <= 1 or Ls <= 1:\n",
    "            continue\n",
    "\n",
    "        \n",
    "        # Try Span-MinED soft alignment\n",
    "        A_full, cov_s, cov_t = None, 0.0, 0.0\n",
    "        if offset_mapping_tea is not None and offset_mapping_stu is not None:\n",
    "            try:\n",
    "                A_full, cov_s, cov_t = _build_span_overlap_matrix(\n",
    "                    offset_mapping_tea[b], offset_mapping_stu[b],\n",
    "                    L_t=Lt, L_s=Ls, device=device\n",
    "                )\n",
    "            except Exception:\n",
    "                A_full = None\n",
    "\n",
    "        use_span = (A_full is not None) and (cov_s >= min_coverage) and (cov_t >= min_coverage)\n",
    "\n",
    "        if use_span:\n",
    "            # token list for special-token downweighting inside compute_token_importance\n",
    "            tea_tokens = tok_teacher.convert_ids_to_tokens(input_ids_tea[b, :Lt].detach().cpu().tolist())\n",
    "\n",
    "            # ---- teacher token importance from LAST teacher layer ----\n",
    "            last_teacher_att = teacher_last_k[-1][b, :, :Lt, :Lt]  # [Ht, Lt, Lt]\n",
    "            tea_imp = compute_token_importance(last_teacher_att, tea_tokens)  # [Lt]\n",
    "\n",
    "            # Only teacher tokens that overlap any student token\n",
    "            valid_cols = (A_full.sum(dim=0) > 0)  # [Lt]\n",
    "            if valid_cols.sum().item() < min_tokens:\n",
    "                use_span = False\n",
    "            else:\n",
    "                imp = tea_imp.clone()\n",
    "                imp[~valid_cols] = -1e9\n",
    "\n",
    "                k_top = max(min_tokens, int(math.ceil(top_frac * float(valid_cols.sum().item()))))\n",
    "                idx_t = torch.topk(imp, k=k_top, largest=True).indices\n",
    "                idx_t = torch.sort(idx_t).values  # keep order\n",
    "\n",
    "                # Student rows that receive any mass after restricting teacher columns\n",
    "                A_sub = A_full[:, idx_t]                    # [Ls, N]\n",
    "                row_sum = A_sub.sum(dim=1)                  # [Ls]\n",
    "                idx_s = torch.nonzero(row_sum > 1e-12).squeeze(-1)\n",
    "\n",
    "                if idx_s.numel() < min_tokens:\n",
    "                    use_span = False\n",
    "                else:\n",
    "                    # Normalize rows on the restricted A\n",
    "                    A_use = A_sub[idx_s]  # [M, N]\n",
    "                    A_use = A_use / A_use.sum(dim=1, keepdim=True).clamp_min(1e-12)\n",
    "\n",
    "                    # confidence gate based on span coverage\n",
    "                    conf = float(min(cov_s, cov_t))\n",
    "\n",
    "                    # If sampling queries, decide query subset using teacher projected attention\n",
    "                    # (use last layer for scoring, then reuse subset for all compared layers)\n",
    "                    q_idx = None\n",
    "                    if query_sample is not None:\n",
    "                        tea_last = teacher_last_k[-1][b, :, :Lt, :Lt]       # [Ht, Lt, Lt]\n",
    "                        tea_sel = tea_last[:, idx_t][:, :, idx_t]           # [Ht, N, N]\n",
    "                        tea_proj_last = _project_teacher_attention_to_student(tea_sel, A_use)  # [Ht, M, M]\n",
    "                        tea_mean = tea_proj_last.mean(dim=0)                # [M, M]\n",
    "                        q_idx = _select_queries_by_focus(tea_mean, max_q=query_sample)\n",
    "                    # else q_idx = all\n",
    "\n",
    "                    for tea_layer, stu_layer in zip(teacher_last_k, student_last_k):\n",
    "                        tea = tea_layer[b, :, :Lt, :Lt]  # [Ht, Lt, Lt]\n",
    "                        stu = stu_layer[b, :, :Ls, :Ls]  # [Hs, Ls, Ls]\n",
    "\n",
    "                        # select teacher tokens (N) then project to student space (M)\n",
    "                        tea_sel = tea[:, idx_t][:, :, idx_t]               # [Ht, N, N]\n",
    "                        tea_proj = _project_teacher_attention_to_student(tea_sel, A_use)  # [Ht, M, M]\n",
    "\n",
    "                        # select student token subset (M)\n",
    "                        stu_sel = stu[:, idx_s][:, :, idx_s]               # [Hs, M, M]\n",
    "\n",
    "                        # optionally sample queries (reduce N in Gram)\n",
    "                        if q_idx is not None:\n",
    "                            tea_proj = tea_proj[:, q_idx][:, :, q_idx]     # [Ht, Q, Q]\n",
    "                            stu_sel = stu_sel[:, q_idx][:, :, q_idx]       # [Hs, Q, Q]\n",
    "\n",
    "                        # For CKA, treat each query row as sample, keys as features:\n",
    "                        # reshape to [H, N, D] where D == N\n",
    "                        # Here: [H, Q, Q] already fits with N=Q, D=Q\n",
    "                        att_loss_total = att_loss_total + conf * cka(stu_sel, tea_proj)\n",
    "                        n_terms += 1\n",
    "\n",
    "        \n",
    "        #  Fallback: MinED-like hard token map\n",
    "        if not use_span:\n",
    "            tea_tokens = tok_teacher.convert_ids_to_tokens(input_ids_tea[b, :Lt].detach().cpu().tolist())\n",
    "            stu_tokens = tok_student.convert_ids_to_tokens(input_ids_stu[b, :Ls].detach().cpu().tolist())\n",
    "\n",
    "            # teacher token importance from last layer\n",
    "            last_teacher_att = teacher_last_k[-1][b, :, :Lt, :Lt]  # [Ht, Lt, Lt]\n",
    "            tea_imp = compute_token_importance(last_teacher_att, tea_tokens)  # [Lt]\n",
    "\n",
    "            reciprocal = build_reciprocal_mapping_from_token_lists(\n",
    "                tea_tokens, stu_tokens,\n",
    "                teacher_special=teacher_special,\n",
    "                student_special=student_special,\n",
    "            )\n",
    "            if len(reciprocal) == 0:\n",
    "                continue\n",
    "\n",
    "            # score reciprocal teacher tokens by importance\n",
    "            tok_score = {}\n",
    "            for t_idx, t_tok in enumerate(tea_tokens):\n",
    "                if t_tok in reciprocal:\n",
    "                    tok_score[t_tok] = max(tok_score.get(t_tok, -1e9), float(tea_imp[t_idx].item()))\n",
    "\n",
    "            if len(tok_score) < min_tokens:\n",
    "                continue\n",
    "\n",
    "            k_top = max(min_tokens, int(math.ceil(top_frac * len(tok_score))))\n",
    "            keep_teacher = [t for t, _ in sorted(tok_score.items(), key=lambda x: x[1], reverse=True)[:k_top]]\n",
    "\n",
    "            # build aligned (t_idx, s_idx) pairs; sort by student order for consistency\n",
    "            pairs = []\n",
    "            for t_tok in keep_teacher:\n",
    "                s_tok = reciprocal[t_tok]\n",
    "                try:\n",
    "                    t_idx = tea_tokens.index(t_tok)\n",
    "                    s_idx = stu_tokens.index(s_tok)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "                if t_idx < Lt and s_idx < Ls:\n",
    "                    pairs.append((t_idx, s_idx))\n",
    "\n",
    "            if len(pairs) < min_tokens:\n",
    "                continue\n",
    "\n",
    "            pairs = sorted(pairs, key=lambda x: x[1])  # sort by student idx\n",
    "            idx_t = torch.tensor([p[0] for p in pairs], device=device, dtype=torch.long)\n",
    "            idx_s = torch.tensor([p[1] for p in pairs], device=device, dtype=torch.long)\n",
    "\n",
    "            for tea_layer, stu_layer in zip(teacher_last_k, student_last_k):\n",
    "                tea = tea_layer[b, :, :Lt, :Lt]  # [Ht, Lt, Lt]\n",
    "                stu = stu_layer[b, :, :Ls, :Ls]  # [Hs, Ls, Ls]\n",
    "\n",
    "                # Compare attention restricted to aligned token set (no min(d) truncation!)\n",
    "                tea_sel = tea[:, idx_t][:, :, idx_t]  # [Ht, N, N]\n",
    "                stu_sel = stu[:, idx_s][:, :, idx_s]  # [Hs, N, N]\n",
    "\n",
    "                # optional query sampling\n",
    "                if query_sample is not None and idx_s.numel() > query_sample:\n",
    "                    tea_mean = tea_sel.mean(dim=0)  # [N,N]\n",
    "                    q_idx = _select_queries_by_focus(tea_mean, max_q=query_sample)\n",
    "                    tea_sel = tea_sel[:, q_idx][:, :, q_idx]\n",
    "                    stu_sel = stu_sel[:, q_idx][:, :, q_idx]\n",
    "\n",
    "                att_loss_total = att_loss_total + cka(stu_sel, tea_sel)\n",
    "                n_terms += 1\n",
    "\n",
    "    if n_terms == 0:\n",
    "        return torch.zeros((), device=device)\n",
    "    return att_loss_total / n_terms\n",
    "\n",
    "# Matryoshka (MRL)\n",
    "def matryoshka_prefix_cosine_loss(student_emb: torch.Tensor,\n",
    "                                  teacher_emb: torch.Tensor,\n",
    "                                  dims,\n",
    "                                  weight_mode: str = \"inverse_sqrt\",\n",
    "                                  eps: float = 1e-8) -> torch.Tensor:\n",
    "    '''\n",
    "    student_emb, teacher_emb: [B, D] with same D.\n",
    "    For each prefix dimension d in dims (+ full D), compute 1 - cosine(student[:d], teacher[:d]).\n",
    "    Optionally weight smaller dims more.\n",
    "    '''\n",
    "    assert student_emb.dim() == 2 and teacher_emb.dim() == 2\n",
    "    B, D = student_emb.shape\n",
    "    assert teacher_emb.shape == (B, D)\n",
    "\n",
    "    dims_list = [int(d) for d in dims if d is not None and int(d) > 0 and int(d) <= D]\n",
    "    if D not in dims_list:\n",
    "        dims_list.append(D)\n",
    "    dims_list = sorted(set(dims_list))\n",
    "\n",
    "    def _w(d):\n",
    "        if weight_mode == \"uniform\":\n",
    "            return 1.0\n",
    "        if weight_mode == \"inverse\":\n",
    "            return 1.0 / max(1.0, float(d))\n",
    "        if weight_mode == \"log\":\n",
    "            return 1.0 / math.log(2.0 + float(d))\n",
    "        # default: inverse_sqrt\n",
    "        return 1.0 / math.sqrt(max(1.0, float(d)))\n",
    "\n",
    "    total = 0.0\n",
    "    wsum = 0.0\n",
    "    for d in dims_list:\n",
    "        s = student_emb[:, :d].float()\n",
    "        t = teacher_emb[:, :d].float()\n",
    "        s = s / (s.norm(dim=-1, keepdim=True) + eps)\n",
    "        t = t / (t.norm(dim=-1, keepdim=True) + eps)\n",
    "        term = (1.0 - (s * t).sum(dim=-1)).mean()\n",
    "        w = _w(d)\n",
    "        total += w * term\n",
    "        wsum += w\n",
    "    return total / max(wsum, 1e-9)\n",
    "\n",
    "# teacher sentence embedding\n",
    "def extract_teacher_sentence_embedding(last_hidden_state: torch.Tensor,\n",
    "                                      input_ids: torch.Tensor,\n",
    "                                      attention_mask: torch.Tensor,\n",
    "                                      tokenizer,\n",
    "                                      embed_token: str = None) -> torch.Tensor:\n",
    "    '''\n",
    "    If embed_token is present in the sequence, use its hidden state.\n",
    "    Otherwise use mean pooling.\n",
    "    Returns: [B, d_t]\n",
    "    '''\n",
    "    if embed_token is not None:\n",
    "        try:\n",
    "            embed_id = tokenizer.convert_tokens_to_ids(embed_token)\n",
    "        except Exception:\n",
    "            embed_id = None\n",
    "        if embed_id is not None:\n",
    "            m = (input_ids == embed_id)\n",
    "            if m.any():\n",
    "                idx = m.float().argmax(dim=1)\n",
    "                has_any = m.any(dim=1)\n",
    "                out = last_hidden_state[:, 0, :].clone()\n",
    "                b_idx = torch.arange(last_hidden_state.size(0), device=last_hidden_state.device)\n",
    "                out[has_any] = last_hidden_state[b_idx[has_any], idx[has_any], :]\n",
    "                return out\n",
    "\n",
    "    return mean_pooling(last_hidden_state, attention_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41ad103",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T08:33:41.285713Z",
     "iopub.status.busy": "2026-01-14T08:33:41.285449Z",
     "iopub.status.idle": "2026-01-14T08:33:41.298149Z",
     "shell.execute_reply": "2026-01-14T08:33:41.297390Z"
    },
    "papermill": {
     "duration": 0.044708,
     "end_time": "2026-01-14T08:33:41.299620",
     "exception": false,
     "start_time": "2026-01-14T08:33:41.254912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# projection layer teacher -> student\n",
    "# infer dims\n",
    "d_s = model_student.config.hidden_size\n",
    "d_t = model_teacher.config.hidden_size\n",
    "\n",
    "# define matryoshka dims now that d_s is known\n",
    "matryoshka_dims = [128, 256, 384, 512, d_s]\n",
    "matryoshka_dims = [d for d in matryoshka_dims if d <= d_s]\n",
    "\n",
    "# create projection if missing / overwritten\n",
    "if (\"proj_t2s\" not in globals()) or (proj_t2s is None) or (not isinstance(proj_t2s, nn.Module)):\n",
    "    print(\"[Fix] Initializing proj_t2s (teacher->student projection).\")\n",
    "    proj_t2s = nn.Linear(d_t, d_s, bias=False).to(device_s)\n",
    "\n",
    "def _optimizer_has_param(opt, p):\n",
    "    pid = id(p)\n",
    "    for g in opt.param_groups:\n",
    "        for q in g.get(\"params\", []):\n",
    "            if id(q) == pid:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "# ensure optimizer includes proj_t2s params\n",
    "if \"optimizer\" in globals():\n",
    "    missing = [p for p in proj_t2s.parameters() if not _optimizer_has_param(optimizer, p)]\n",
    "    if len(missing) > 0:\n",
    "        print(f\"[Fix] Adding proj_t2s params to optimizer (missing {len(missing)} tensors).\")\n",
    "        optimizer.add_param_group({\"params\": proj_t2s.parameters(), \"lr\": LR})\n",
    "else:\n",
    "    raise RuntimeError(\"optimizer not found. Run the optimizer/scheduler cell before this one.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b57f0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-14T08:33:41.360896Z",
     "iopub.status.busy": "2026-01-14T08:33:41.360666Z",
     "iopub.status.idle": "2026-01-14T08:55:21.015745Z",
     "shell.execute_reply": "2026-01-14T08:55:21.014750Z"
    },
    "papermill": {
     "duration": 1299.687897,
     "end_time": "2026-01-14T08:55:21.017466",
     "exception": false,
     "start_time": "2026-01-14T08:33:41.329569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TRAINING LOOP \n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "global_step = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_student.train()\n",
    "    total_loss, n_items = 0.0, 0\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "    for batch in pbar:\n",
    "        batch_s, batch_t = {}, {}\n",
    "        for k, v in batch.items():\n",
    "            if not torch.is_tensor(v):\n",
    "                continue\n",
    "            if k.endswith(\"_stu\") or k == \"labels\":\n",
    "                batch_s[k] = v.to(device_s, non_blocking=True)\n",
    "            if k.endswith(\"_tea\"):\n",
    "                batch_t[k] = v.to(device_t, non_blocking=True)\n",
    "\n",
    "        # scheduled weights\n",
    "        beta_mrl = beta_mrl_max * ramp(global_step, mrl_start, mrl_ramp)\n",
    "        alpha_attn = alpha_attn_max * ramp(global_step, att_start, att_ramp)\n",
    "\n",
    "        need_att = (alpha_attn > 0) and (att_every > 0) and (global_step % att_every == 0)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with autocast(enabled=torch.cuda.is_available()):\n",
    "            # ================== TEACHER (device_t, no grad) ==================\n",
    "            with torch.inference_mode():\n",
    "                t_out1 = model_teacher(\n",
    "                    input_ids=batch_t[\"input_ids1_tea\"],\n",
    "                    attention_mask=batch_t[\"attention_mask1_tea\"],\n",
    "                    output_attentions=need_att,\n",
    "                    return_dict=True,\n",
    "                )\n",
    "                T_last1 = t_out1.last_hidden_state  # [B, L_t, d_t]\n",
    "\n",
    "                T_sent = extract_teacher_sentence_embedding(\n",
    "                    last_hidden_state=T_last1,\n",
    "                    input_ids=batch_t[\"input_ids1_tea\"],\n",
    "                    attention_mask=batch_t[\"attention_mask1_tea\"],\n",
    "                    tokenizer=tok_teacher,\n",
    "                    embed_token=teacher_special,   # \"<|embed|>\" by default\n",
    "                )  # [B, d_t]\n",
    "\n",
    "                # move sentence embedding only\n",
    "                T_sent_s = T_sent.to(device_s, non_blocking=True)\n",
    "                T_emb_s = proj_t2s(T_sent_s)  # [B, d_s]\n",
    "\n",
    "                if need_att:\n",
    "                    T_atts = [att.to(device_s, non_blocking=True) for att in t_out1.attentions]\n",
    "                else:\n",
    "                    T_atts = None\n",
    "\n",
    "            # ================== STUDENT (device_s) ==================\n",
    "            s_out1 = model_student(\n",
    "                input_ids=batch_s[\"input_ids1_stu\"],\n",
    "                attention_mask=batch_s[\"attention_mask1_stu\"],\n",
    "                output_attentions=need_att,\n",
    "                return_dict=True,\n",
    "            )\n",
    "            s_out2 = model_student(\n",
    "                input_ids=batch_s[\"input_ids2_stu\"],\n",
    "                attention_mask=batch_s[\"attention_mask2_stu\"],\n",
    "                return_dict=True,\n",
    "            )\n",
    "\n",
    "            S_last1 = s_out1.last_hidden_state\n",
    "            S_last2 = s_out2.last_hidden_state\n",
    "\n",
    "            S_emb1 = get_student_sentence_emb(S_last1, batch_s[\"attention_mask1_stu\"], student_pool)\n",
    "            S_emb2 = get_student_sentence_emb(S_last2, batch_s[\"attention_mask2_stu\"], student_pool)\n",
    "\n",
    "            # (A) Main SimCSE InfoNCE\n",
    "            loss_task, _ = info_nce(S_emb1, S_emb2)\n",
    "\n",
    "            # (B) MRL (Matryoshka) distillation\n",
    "            mrl_1 = matryoshka_prefix_cosine_loss(\n",
    "                student_emb=S_emb1,\n",
    "                teacher_emb=T_emb_s,\n",
    "                dims=matryoshka_dims,\n",
    "                weight_mode=mrl_weight_mode,\n",
    "            )\n",
    "            mrl_2 = matryoshka_prefix_cosine_loss(\n",
    "                student_emb=S_emb2,\n",
    "                teacher_emb=T_emb_s,\n",
    "                dims=matryoshka_dims,\n",
    "                weight_mode=mrl_weight_mode,\n",
    "            )\n",
    "            mrl_loss = 0.5 * (mrl_1 + mrl_2)\n",
    "\n",
    "            # (C) IRA/CKA attention alignment (optional)\n",
    "            if need_att:\n",
    "                S_atts = s_out1.attentions\n",
    "                att_loss = compute_att_loss_2(\n",
    "                    teacher_atts=T_atts,\n",
    "                    student_atts=S_atts,\n",
    "                    input_ids_tea=batch_t[\"input_ids1_tea\"].to(device_s, non_blocking=True),\n",
    "                    input_ids_stu=batch_s[\"input_ids1_stu\"],\n",
    "                    attention_mask_tea=batch_t[\"attention_mask1_tea\"].to(device_s, non_blocking=True),\n",
    "                    attention_mask_stu=batch_s[\"attention_mask1_stu\"],\n",
    "                    tok_teacher=tok_teacher,\n",
    "                    tok_student=tok_student,\n",
    "                    k=k_ira,\n",
    "                    device=device_s,\n",
    "                    teacher_special=teacher_special,\n",
    "                    student_special=student_special,\n",
    "                    top_frac=top_frac,\n",
    "                    min_tokens=min_tokens,\n",
    "                    offset_mapping_tea=(batch_t[\"offset_mapping1_tea\"].to(device_s, non_blocking=True)\n",
    "                                       if \"offset_mapping1_tea\" in batch_t else None),\n",
    "                    offset_mapping_stu=(batch_s[\"offset_mapping1_stu\"]\n",
    "                                       if \"offset_mapping1_stu\" in batch_s else None),\n",
    "                )\n",
    "            else:\n",
    "                att_loss = torch.tensor(0.0, device=device_s)\n",
    "\n",
    "            kd_sum = alpha_attn * att_loss + beta_mrl * mrl_loss\n",
    "\n",
    "            # Total loss\n",
    "            loss = (w_task * loss_task) + (alpha_kd * kd_sum)\n",
    "            loss = loss.float()\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "\n",
    "        # logging\n",
    "        bs = next(iter(batch_s.values())).size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        n_items += bs\n",
    "        avg_loss = total_loss / max(1, n_items)\n",
    "\n",
    "        pbar.set_postfix({\n",
    "            \"avg\": f\"{avg_loss:.4f}\",\n",
    "            \"task\": f\"{loss_task.detach().float().item():.3f}\",\n",
    "            \"mrl\": f\"{mrl_loss.detach().float().item():.3f}\",\n",
    "            \"att\": f\"{att_loss.detach().float().item():.3f}\",\n",
    "            \"β_mrl\": f\"{beta_mrl:.2f}\",\n",
    "            \"α_att\": f\"{alpha_attn:.3f}\",\n",
    "            \"att?\": int(need_att),\n",
    "        })\n",
    "\n",
    "        global_step += 1\n",
    "\n",
    "        # cleanup\n",
    "        del S_last1, S_last2, S_emb1, S_emb2, T_last1, T_sent, T_sent_s, T_emb_s, mrl_1, mrl_2, mrl_loss, loss\n",
    "        if need_att:\n",
    "            del T_atts, S_atts\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # eval hooks\n",
    "    eval_classification_task(model_student, test_cls_tasks)\n",
    "    eval_pair_task(model_student, test_pair_tasks)\n",
    "    eval_sts_task(model_student, test_sts_tasks)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8883594,
     "sourceId": 13939420,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1396.336589,
   "end_time": "2026-01-14T08:55:24.364983",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-14T08:32:08.028394",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0336a2c4efdc42f388c7bc86ec762534": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "03e265a291de4389b22e0267b36e0790": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "050b36a5f8064fd7bfa7547077a3ad5d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "06ff8833ca3b46f6af48b859d01fd852": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0336a2c4efdc42f388c7bc86ec762534",
       "placeholder": "​",
       "style": "IPY_MODEL_050b36a5f8064fd7bfa7547077a3ad5d",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "0710227e91494b168ecee8d32612f8da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f7ead5f2d112446681282f17f144e3b7",
       "placeholder": "​",
       "style": "IPY_MODEL_c849efe1b0944eb88da2319fef1611f6",
       "tabbable": null,
       "tooltip": null,
       "value": " 5.07M/5.07M [00:00&lt;00:00, 31.3MB/s]"
      }
     },
     "087b8970518445eaacc1a45d4cd05342": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0c201dcc2c124b898c2d5e23395b2850": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "11790b1c5843408baaa7870974aaa90a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0c201dcc2c124b898c2d5e23395b2850",
       "placeholder": "​",
       "style": "IPY_MODEL_20a8c30f52a9458cbda2f3583ba07727",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer.json: 100%"
      }
     },
     "11bf9f5dd7c743a0a340a747eecab76b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b2c576edb8314adc9adbe25badf7a1fc",
       "placeholder": "​",
       "style": "IPY_MODEL_703ad44f930443c797a6e7175e222416",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "12158cca41cb44a29a3a11ebb77c1ee8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "124c5d1876684429bc3fb193b07ec7d5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_06ff8833ca3b46f6af48b859d01fd852",
        "IPY_MODEL_75b784e071f9407f98875b36bdb5e005",
        "IPY_MODEL_99b70c8c7fa6494eaf138bbbb59ddc19"
       ],
       "layout": "IPY_MODEL_192bc78de2104432beb7f2b6d5a7768a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "13f7c97fb68a43e6ac64809f673fdd1b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "192bc78de2104432beb7f2b6d5a7768a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1c3ec4a5f9584cd6837806907f5f550b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_269d8a31d2e248919c66747feb0d249b",
       "placeholder": "​",
       "style": "IPY_MODEL_03e265a291de4389b22e0267b36e0790",
       "tabbable": null,
       "tooltip": null,
       "value": " 232k/? [00:00&lt;00:00, 9.20MB/s]"
      }
     },
     "1f48d687142d4322817115a1d87d52d3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "20a8c30f52a9458cbda2f3583ba07727": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "234b767c24704fb3bbf307ef8899e2ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d4399a39b7c94bfc813e311e9319eb04",
       "placeholder": "​",
       "style": "IPY_MODEL_60097fd6b6694f3daf8c58f8ac7ee66f",
       "tabbable": null,
       "tooltip": null,
       "value": " 62.7M/62.7M [00:01&lt;00:00, 36.3MB/s]"
      }
     },
     "245aa60ad7b84e119e3d90d42f5bec83": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "25d2f1dc780f4bfd94fb2b6ae7c130b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "260a7111a6b845f09fe622c8fa5adcef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "267569b2ab6745199f6a34d36bb7b916": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "269d8a31d2e248919c66747feb0d249b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "28cd7b6aa7234c0bb65529fa4b85b736": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "292b4f7da0784fdda141c8ffe983c27b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2f7c6f06fd954933a9d5887e0e7790ac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a6658e5ed5ef4ed2aa68b9796c999f06",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_af3d8eed1223479aac82c170eec06479",
       "tabbable": null,
       "tooltip": null,
       "value": 1
      }
     },
     "33d88795d24c477c802b3c51de3cf3b6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5efc01072baa4deb8346903ed3841e5c",
       "max": 444,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ae4f713c32f945c288c9edd46ab4913c",
       "tabbable": null,
       "tooltip": null,
       "value": 444
      }
     },
     "347d25574feb4b12a6863d66827884bf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "362c9e0acbba4b708237932f57777c6a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3aeee6db06fc43d182e8a66c4bb21041": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3ba60a45639948f9af4eff7ac38a8fc8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ab0c7800e9484f16934f22f185b8ae52",
       "max": 2271145830,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_28cd7b6aa7234c0bb65529fa4b85b736",
       "tabbable": null,
       "tooltip": null,
       "value": 2271145830
      }
     },
     "3d405e0856534d04a70430550c10ea6a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3d435538630244a9aa0cf3f36f47fd17": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cfae0690673044a281f58d41823aebb9",
       "placeholder": "​",
       "style": "IPY_MODEL_dd0155917807420096dca289484df660",
       "tabbable": null,
       "tooltip": null,
       "value": "pytorch_model.bin: 100%"
      }
     },
     "4403ec5f488b402ea92209253627ad30": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "44190cb1129f48ffaed00f6ce7ff6f7c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6965cb9ecb2c43ee9d302dd12197b5ad",
       "placeholder": "​",
       "style": "IPY_MODEL_cd6ba0f115d2471d96279f7fdb858006",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: "
      }
     },
     "47ad25c0f71e4c9ba377be44f1448c8b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4c88e3414cc4496ba6902f58784c039e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_52832760f4574b8081cb58b967676534",
       "max": 5069051,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_652bc4021ed84312a2156d01d347f947",
       "tabbable": null,
       "tooltip": null,
       "value": 5069051
      }
     },
     "4d582995581e4159a2298bdc26c02fad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3aeee6db06fc43d182e8a66c4bb21041",
       "placeholder": "​",
       "style": "IPY_MODEL_3d405e0856534d04a70430550c10ea6a",
       "tabbable": null,
       "tooltip": null,
       "value": " 687/687 [00:00&lt;00:00, 81.4kB/s]"
      }
     },
     "4e210e5b84244bd3a4501cba0fb4efab": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4fb937dedd184a508e239a713b2cf174": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_11790b1c5843408baaa7870974aaa90a",
        "IPY_MODEL_dabdcb29befb4ab1bb8ecaadc3c7a8bd",
        "IPY_MODEL_fb0ee75165214552a68f8a885c4791bc"
       ],
       "layout": "IPY_MODEL_4e210e5b84244bd3a4501cba0fb4efab",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4feb9aabe6234b85b0a2d82b9e5bac74": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "52832760f4574b8081cb58b967676534": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5ab49043626d42c1a8a8935006e0c425": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5bd477bdb2a94714b71433d8470b4531": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5d4ccaa7aa014cc6ab9f0c08d3871974": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_44190cb1129f48ffaed00f6ce7ff6f7c",
        "IPY_MODEL_2f7c6f06fd954933a9d5887e0e7790ac",
        "IPY_MODEL_1c3ec4a5f9584cd6837806907f5f550b"
       ],
       "layout": "IPY_MODEL_d0286306f7e74d62a19d27b873b61bf8",
       "tabbable": null,
       "tooltip": null
      }
     },
     "5efc01072baa4deb8346903ed3841e5c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "60097fd6b6694f3daf8c58f8ac7ee66f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "637bb7b2efaa4c4795b956ee9e9938c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b73a357387414c7ba0f3cb4666f0d3b4",
       "max": 687,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b39c883f8e6642deb436a14753d261ed",
       "tabbable": null,
       "tooltip": null,
       "value": 687
      }
     },
     "652bc4021ed84312a2156d01d347f947": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6965cb9ecb2c43ee9d302dd12197b5ad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6aaf05ab218c47458de4298d153b1a20": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8ba632c89d7347e6a80769dce1c0dc37",
        "IPY_MODEL_637bb7b2efaa4c4795b956ee9e9938c1",
        "IPY_MODEL_4d582995581e4159a2298bdc26c02fad"
       ],
       "layout": "IPY_MODEL_267569b2ab6745199f6a34d36bb7b916",
       "tabbable": null,
       "tooltip": null
      }
     },
     "6b3a4b535f694e088f97e177c733d072": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "703ad44f930443c797a6e7175e222416": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "75b784e071f9407f98875b36bdb5e005": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_347d25574feb4b12a6863d66827884bf",
       "max": 409,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_245aa60ad7b84e119e3d90d42f5bec83",
       "tabbable": null,
       "tooltip": null,
       "value": 409
      }
     },
     "7be72616772f4c55a2e8fa1a0a254f4b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7ef759cd93034c5bab0d35b2ea09bcd9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_df9fc17d75774b97ae056e18e768970d",
        "IPY_MODEL_3ba60a45639948f9af4eff7ac38a8fc8",
        "IPY_MODEL_d6cfeeb246f543a0820d9cd2ba74378c"
       ],
       "layout": "IPY_MODEL_4403ec5f488b402ea92209253627ad30",
       "tabbable": null,
       "tooltip": null
      }
     },
     "7ffe5c179a584beb87c4bfb27dabe747": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6b3a4b535f694e088f97e177c733d072",
       "placeholder": "​",
       "style": "IPY_MODEL_a531b01834994532bcdabb893dd59210",
       "tabbable": null,
       "tooltip": null,
       "value": " 444/444 [00:00&lt;00:00, 59.8kB/s]"
      }
     },
     "81f8a1f77cf04d20b6d568430b5b9901": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "83a901b88c484c3c9e27bc5d42ec2dd5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "892d943c47d34b73b294a1ca4f7b4716": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "89e4546a5b2747b89f5e27c3a245069b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8ba632c89d7347e6a80769dce1c0dc37": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_087b8970518445eaacc1a45d4cd05342",
       "placeholder": "​",
       "style": "IPY_MODEL_7be72616772f4c55a2e8fa1a0a254f4b",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "953174f4ea30410daa2714db333733c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5bd477bdb2a94714b71433d8470b4531",
       "max": 62747391,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_13f7c97fb68a43e6ac64809f673fdd1b",
       "tabbable": null,
       "tooltip": null,
       "value": 62747391
      }
     },
     "99b70c8c7fa6494eaf138bbbb59ddc19": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c60b55c7d9f84407a517f610e873b033",
       "placeholder": "​",
       "style": "IPY_MODEL_e6ca52f101654e0e93f1ecca8862497d",
       "tabbable": null,
       "tooltip": null,
       "value": " 409/409 [00:00&lt;00:00, 50.6kB/s]"
      }
     },
     "a531b01834994532bcdabb893dd59210": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a6658e5ed5ef4ed2aa68b9796c999f06": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "a916dbd5de234e2ca7309422c69388b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_afee7f2807e84916bbb46555c12e66c0",
        "IPY_MODEL_fcc99d35d2164dc0b2cf64cccbd824ed",
        "IPY_MODEL_e781e7db84b543f193895bb8f7d107fb"
       ],
       "layout": "IPY_MODEL_dfcdc29384414fa8bda96b6c3dc931d9",
       "tabbable": null,
       "tooltip": null
      }
     },
     "a9f9fcf793214ae58ef3e93031dd241f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ab0c7800e9484f16934f22f185b8ae52": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ae4f713c32f945c288c9edd46ab4913c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "af06c59c87504ff788831fc48991786a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "af3d8eed1223479aac82c170eec06479": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "af5bb55c39df425ab8bc267e0c0c0cc7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_cb87d1a04e6f47d5b42007c20ee34e43",
        "IPY_MODEL_4c88e3414cc4496ba6902f58784c039e",
        "IPY_MODEL_0710227e91494b168ecee8d32612f8da"
       ],
       "layout": "IPY_MODEL_47ad25c0f71e4c9ba377be44f1448c8b",
       "tabbable": null,
       "tooltip": null
      }
     },
     "afee7f2807e84916bbb46555c12e66c0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1f48d687142d4322817115a1d87d52d3",
       "placeholder": "​",
       "style": "IPY_MODEL_f325e4eca81d4e78b5329a23d5ff3db9",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     },
     "b08d23f0fc484acca30358669f35fb48": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3d435538630244a9aa0cf3f36f47fd17",
        "IPY_MODEL_953174f4ea30410daa2714db333733c8",
        "IPY_MODEL_234b767c24704fb3bbf307ef8899e2ef"
       ],
       "layout": "IPY_MODEL_362c9e0acbba4b708237932f57777c6a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "b2c576edb8314adc9adbe25badf7a1fc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b39c883f8e6642deb436a14753d261ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b5d43241d8b549f1a031d40cf06fbe72": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b73a357387414c7ba0f3cb4666f0d3b4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c3865ebb29cd4f70bbdf067c1ff550cd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c60b55c7d9f84407a517f610e873b033": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c849efe1b0944eb88da2319fef1611f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cb87d1a04e6f47d5b42007c20ee34e43": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_12158cca41cb44a29a3a11ebb77c1ee8",
       "placeholder": "​",
       "style": "IPY_MODEL_292b4f7da0784fdda141c8ffe983c27b",
       "tabbable": null,
       "tooltip": null,
       "value": "sentencepiece.bpe.model: 100%"
      }
     },
     "cd6ba0f115d2471d96279f7fdb858006": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cfae0690673044a281f58d41823aebb9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d0286306f7e74d62a19d27b873b61bf8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d4399a39b7c94bfc813e311e9319eb04": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d6cfeeb246f543a0820d9cd2ba74378c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4feb9aabe6234b85b0a2d82b9e5bac74",
       "placeholder": "​",
       "style": "IPY_MODEL_83a901b88c484c3c9e27bc5d42ec2dd5",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.27G/2.27G [00:05&lt;00:00, 1.32GB/s]"
      }
     },
     "dabdcb29befb4ab1bb8ecaadc3c7a8bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_260a7111a6b845f09fe622c8fa5adcef",
       "max": 17098108,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b5d43241d8b549f1a031d40cf06fbe72",
       "tabbable": null,
       "tooltip": null,
       "value": 17098108
      }
     },
     "dd0155917807420096dca289484df660": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "df9fc17d75774b97ae056e18e768970d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_89e4546a5b2747b89f5e27c3a245069b",
       "placeholder": "​",
       "style": "IPY_MODEL_c3865ebb29cd4f70bbdf067c1ff550cd",
       "tabbable": null,
       "tooltip": null,
       "value": "pytorch_model.bin: 100%"
      }
     },
     "dfcdc29384414fa8bda96b6c3dc931d9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e6ca52f101654e0e93f1ecca8862497d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e781e7db84b543f193895bb8f7d107fb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5ab49043626d42c1a8a8935006e0c425",
       "placeholder": "​",
       "style": "IPY_MODEL_25d2f1dc780f4bfd94fb2b6ae7c130b2",
       "tabbable": null,
       "tooltip": null,
       "value": " 964/964 [00:00&lt;00:00, 136kB/s]"
      }
     },
     "ebbb59e156db4e11b3a57fde3bb033eb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f21b323132a249119d6228f3349e35c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_11bf9f5dd7c743a0a340a747eecab76b",
        "IPY_MODEL_33d88795d24c477c802b3c51de3cf3b6",
        "IPY_MODEL_7ffe5c179a584beb87c4bfb27dabe747"
       ],
       "layout": "IPY_MODEL_af06c59c87504ff788831fc48991786a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "f325e4eca81d4e78b5329a23d5ff3db9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f7ead5f2d112446681282f17f144e3b7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fb0ee75165214552a68f8a885c4791bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_81f8a1f77cf04d20b6d568430b5b9901",
       "placeholder": "​",
       "style": "IPY_MODEL_a9f9fcf793214ae58ef3e93031dd241f",
       "tabbable": null,
       "tooltip": null,
       "value": " 17.1M/17.1M [00:00&lt;00:00, 87.8MB/s]"
      }
     },
     "fcc99d35d2164dc0b2cf64cccbd824ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ebbb59e156db4e11b3a57fde3bb033eb",
       "max": 964,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_892d943c47d34b73b294a1ca4f7b4716",
       "tabbable": null,
       "tooltip": null,
       "value": 964
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
